From patchwork Wed Dec 26 01:54:59 2018
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Wei Yang <richardw.yang@linux.intel.com>
X-Patchwork-Id: 10742773
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id A1B3813BF
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 26 Dec 2018 01:55:45 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8C3A428753
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 26 Dec 2018 01:55:45 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7B067288DA; Wed, 26 Dec 2018 01:55:45 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.9 required=2.0 tests=BAYES_00,MAILING_LIST_MULTI,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5502B28753
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 26 Dec 2018 01:55:41 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1725962AbeLZBzk (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 25 Dec 2018 20:55:40 -0500
Received: from mga01.intel.com ([192.55.52.88]:11275 "EHLO mga01.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1725953AbeLZBzk (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 25 Dec 2018 20:55:40 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga006.jf.intel.com ([10.7.209.51])
  by fmsmga101.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
 25 Dec 2018 17:55:39 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,399,1539673200";
   d="scan'208";a="103323746"
Received: from richard.sh.intel.com (HELO localhost) ([10.239.36.8])
  by orsmga006.jf.intel.com with ESMTP; 25 Dec 2018 17:55:38 -0800
From: Wei Yang <richardw.yang@linux.intel.com>
To: x86@kernel.org, kvm@vger.kernel.org
Cc: rkrcmar@redhat.com, pbonzini@redhat.com,
        Wei Yang <richardw.yang@linux.intel.com>
Subject: [PATCH] kvm, x86: simplify manipulation of ASYNC_PF_PER_VCPU on x86
Date: Wed, 26 Dec 2018 09:54:59 +0800
Message-Id: <20181226015459.10901-1-richardw.yang@linux.intel.com>
X-Mailer: git-send-email 2.19.1
MIME-Version: 1.0
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

In generic code kvm_setup_async_pf() checks the async_pf size by:

    if (vcpu->async_pf.queued >= ASYNC_PF_PER_VCPU)

While in x86, we define the array as:

    gfn_t gfns[roundup_pow_of_two(ASYNC_PF_PER_VCPU)];

And each time we compare the index like this:

    i < roundup_pow_of_two(ASYNC_PF_PER_VCPU)

The behavior is correct now, while not consistent with generic code.

As for now ASYNC_PF_PER_VCPU is defined as 64, which is already a power of
2. This patch introduces ASYNC_PF_PER_VCPU_ORDER and rewrite the definition
as:

    #define ASYNC_PF_PER_VCPU_ORDER 6
    #define ASYNC_PF_PER_VCPU      (1 << ASYNC_PF_PER_VCPU_ORDER)

By doing so, we can remove the roundup_pow_of_two()/order_base_2() helpers
when access async_pf on x86. And this make code consistent between
generic and x86.

Signed-off-by: Wei Yang <richardw.yang@linux.intel.com>
---
v2: Radim suggest to change platform code instead of generic code.
---
 arch/x86/include/asm/kvm_host.h | 5 +++--
 arch/x86/kvm/x86.c              | 8 ++++----
 2 files changed, 7 insertions(+), 6 deletions(-)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index fbda5a917c5b..570ddc74a4e5 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -134,7 +134,8 @@ static inline gfn_t gfn_to_index(gfn_t gfn, gfn_t base_gfn, int level)
 #define KVM_NR_FIXED_MTRR_REGION 88
 #define KVM_NR_VAR_MTRR 8
 
-#define ASYNC_PF_PER_VCPU 64
+#define ASYNC_PF_PER_VCPU_ORDER 6
+#define ASYNC_PF_PER_VCPU (1 << ASYNC_PF_PER_VCPU_ORDER)
 
 enum kvm_reg {
 	VCPU_REGS_RAX = 0,
@@ -726,7 +727,7 @@ struct kvm_vcpu_arch {
 
 	struct {
 		bool halted;
-		gfn_t gfns[roundup_pow_of_two(ASYNC_PF_PER_VCPU)];
+		gfn_t gfns[ASYNC_PF_PER_VCPU];
 		struct gfn_to_hva_cache data;
 		u64 msr_val;
 		u32 id;
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index d02937760c3b..ff5296cbc9da 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -218,7 +218,7 @@ static int emulator_fix_hypercall(struct x86_emulate_ctxt *ctxt);
 static inline void kvm_async_pf_hash_reset(struct kvm_vcpu *vcpu)
 {
 	int i;
-	for (i = 0; i < roundup_pow_of_two(ASYNC_PF_PER_VCPU); i++)
+	for (i = 0; i < ASYNC_PF_PER_VCPU; i++)
 		vcpu->arch.apf.gfns[i] = ~0;
 }
 
@@ -9488,12 +9488,12 @@ void kvm_arch_async_page_ready(struct kvm_vcpu *vcpu, struct kvm_async_pf *work)
 
 static inline u32 kvm_async_pf_hash_fn(gfn_t gfn)
 {
-	return hash_32(gfn & 0xffffffff, order_base_2(ASYNC_PF_PER_VCPU));
+	return hash_32(gfn & 0xffffffff, ASYNC_PF_PER_VCPU_ORDER);
 }
 
 static inline u32 kvm_async_pf_next_probe(u32 key)
 {
-	return (key + 1) & (roundup_pow_of_two(ASYNC_PF_PER_VCPU) - 1);
+	return (key + 1) & (ASYNC_PF_PER_VCPU - 1);
 }
 
 static void kvm_add_async_pf_gfn(struct kvm_vcpu *vcpu, gfn_t gfn)
@@ -9511,7 +9511,7 @@ static u32 kvm_async_pf_gfn_slot(struct kvm_vcpu *vcpu, gfn_t gfn)
 	int i;
 	u32 key = kvm_async_pf_hash_fn(gfn);
 
-	for (i = 0; i < roundup_pow_of_two(ASYNC_PF_PER_VCPU) &&
+	for (i = 0; i < ASYNC_PF_PER_VCPU &&
 		     (vcpu->arch.apf.gfns[key] != gfn &&
 		      vcpu->arch.apf.gfns[key] != ~0); i++)
 		key = kvm_async_pf_next_probe(key);

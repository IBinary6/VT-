From patchwork Fri Jun  7 06:02:48 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
X-Patchwork-Submitter: Eugene Korenevsky <ekorenevsky@gmail.com>
X-Patchwork-Id: 10980793
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id C1C3114B6
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:02:54 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id AB25228AF3
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:02:54 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9C25B28B00; Fri,  7 Jun 2019 06:02:54 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 44FB028AF3
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:02:54 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726248AbfFGGCx (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Fri, 7 Jun 2019 02:02:53 -0400
Received: from mail-lj1-f196.google.com ([209.85.208.196]:39050 "EHLO
        mail-lj1-f196.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726023AbfFGGCx (ORCPT <rfc822;kvm@vger.kernel.org>);
        Fri, 7 Jun 2019 02:02:53 -0400
Received: by mail-lj1-f196.google.com with SMTP id v18so656457ljh.6
        for <kvm@vger.kernel.org>; Thu, 06 Jun 2019 23:02:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=date:from:to:cc:subject:message-id:mail-followup-to:mime-version
         :content-disposition:content-transfer-encoding:user-agent;
        bh=ehLz7BXTzkKePFW0yF7URiswDSc0WhRHwoIzOdFE8Ps=;
        b=umzU0dMq+Sp/wwjjYsipPLfqqxFuDWVrFi9CQotVm4NBdoQ2MnLszcBTeQsERtXWfI
         GBTXHyklJjxt9lGT483f/Y46V6TyYnvUjHKifZcQ3LMcW7ci1fYriCLds2uQtT0CvMfl
         /N68n3f/oCgpYOqap16JTAy2CfnN+ELdkW+YCKDrltAkWNOZKLvaJ1qCWyLqsLw/cyr/
         yI+AItCOuXdHdBkG3EJDqyWc5ekqlO3tkF0r7Zf8qOX8pEj91sZpIImj9kg7dJsZ4NZ1
         8GLZcte8PoIWlS/qSsBt1a8SVgQ5/5r228lAcauZGV/9jVNpmhu4bTB6HYqNmfaolNy9
         D5Fw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:from:to:cc:subject:message-id
         :mail-followup-to:mime-version:content-disposition
         :content-transfer-encoding:user-agent;
        bh=ehLz7BXTzkKePFW0yF7URiswDSc0WhRHwoIzOdFE8Ps=;
        b=OT4ArdiUHg6IF1GW4bnBHjJlO9o9VR9Tzp+15MfFrZMh5z8OmJBKRtgNuyXqgNTM7d
         orboyQS7DZOvEU3uczZrFnVplcMZDlqRNpL0bFP1GVKvHoDOvds+Yb+61ASuJ5zjaMM3
         rZ5QB04VHk9UNLvUd2SARlqHFGuVWw5eliWkJezpO50fgHhFSXio6XmYHDc6k5gKtYEi
         eIr4rHothNimNvZrVlT6hhJ2UYviXSdx7XwM4YXip62jBqDIr+nwBon0zJIg2tKVEK77
         coFBhtppANnaUJGGwA/5pL0Re1fLyeHjy4woPDF4oHgMzBUGmFYfNwb23R6WWstcMFga
         tbIg==
X-Gm-Message-State: APjAAAXVXeNlAGvFQJ29F3DW065Z0e8C9LxG4ezZXcHz+ETTkUZz34vB
        cYCffvT7ed2HnfTv+MTxNgM7PsGl
X-Google-Smtp-Source: 
 APXvYqwZfKz1eAhOKQjv+JiUs2HTKUEX61tp7k0nam7vsAf33ysoCY9zUJp5KV6Vsu8KbrE81ue3Pw==
X-Received: by 2002:a2e:9f41:: with SMTP id v1mr20701975ljk.66.1559887370937;
        Thu, 06 Jun 2019 23:02:50 -0700 (PDT)
Received: from dnote ([31.173.87.118])
        by smtp.gmail.com with ESMTPSA id
 s20sm208428lfb.95.2019.06.06.23.02.49
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Thu, 06 Jun 2019 23:02:50 -0700 (PDT)
Date: Fri, 7 Jun 2019 09:02:48 +0300
From: Eugene Korenevsky <ekorenevsky@gmail.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>
Subject: [PATCH v5 1/3] kvm: vmx: fix limit checking in get_vmx_mem_address()
Message-ID: <20190607060248.GA29087@dnote>
Mail-Followup-To: Eugene Korenevsky <ekorenevsky@gmail.com>,
        kvm@vger.kernel.org, Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Disposition: inline
User-Agent: Mutt/1.12.0 (2019-05-25)
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

Intel SDM vol. 3, 5.3:
The processor causes a
general-protection exception (or, if the segment is SS, a stack-fault
exception) any time an attempt is made to access the following addresses
in a segment:
- A byte at an offset greater than the effective limit
- A word at an offset greater than the (effective-limit – 1)
- A doubleword at an offset greater than the (effective-limit – 3)
- A quadword at an offset greater than the (effective-limit – 7)

Therefore, the generic limit checking error condition must be

exn = (off > limit + 1 - access_len) = (off + access_len - 1 > limit)

but not

exn = (off + access_len > limit)

as for now.

Also avoid integer overflow of `off` at 32-bit KVM by casting it to u64.

Note: access length is currently sizeof(u64) which is incorrect. This
will be fixed in the subsequent patch.

Signed-off-by: Eugene Korenevsky <ekorenevsky@gmail.com>
Reviewed-by: Sean Christopherson <sean.j.christopherson@intel.com>
---
Changes in v3 since v2: fixed limit checking condition to avoid underflow;
added note
Changes in v4 since v3: fixed `off` overflow at 32-bit by casting to u64

 arch/x86/kvm/vmx/nested.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index f1a69117ac0f..1a51bff129a8 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -4115,7 +4115,7 @@ int get_vmx_mem_address(struct kvm_vcpu *vcpu, unsigned long exit_qualification,
 		 */
 		if (!(s.base == 0 && s.limit == 0xffffffff &&
 		     ((s.type & 8) || !(s.type & 4))))
-			exn = exn || (off + sizeof(u64) > s.limit);
+			exn = exn || ((u64)off + sizeof(u64) - 1 > s.limit);
 	}
 	if (exn) {
 		kvm_queue_exception_e(vcpu,

From patchwork Fri Jun  7 06:03:21 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Eugene Korenevsky <ekorenevsky@gmail.com>
X-Patchwork-Id: 10980795
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 534B414B6
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:03:29 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3D32A28AF5
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:03:29 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 2BDE728B0D; Fri,  7 Jun 2019 06:03:29 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 88E7428AF5
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:03:28 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726336AbfFGGD1 (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Fri, 7 Jun 2019 02:03:27 -0400
Received: from mail-lj1-f195.google.com ([209.85.208.195]:36144 "EHLO
        mail-lj1-f195.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725902AbfFGGD1 (ORCPT <rfc822;kvm@vger.kernel.org>);
        Fri, 7 Jun 2019 02:03:27 -0400
Received: by mail-lj1-f195.google.com with SMTP id i21so664635ljj.3
        for <kvm@vger.kernel.org>; Thu, 06 Jun 2019 23:03:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=date:from:to:cc:subject:message-id:mail-followup-to:mime-version
         :content-disposition:user-agent;
        bh=8GpH2/AsoDcjNS5c7qWj4v9T2WnCo4ViW9xFu4Gblkk=;
        b=T+PtGM0wWj4y1IS+yGvIO8iak2dMcl91yDxkIUZQ+00oillVCndvPyfvAty4IzIrOF
         OOrEWhgqTgfxy74CqJZCF2DQhd+cg/PrrF2jneAvLuFTLLX8zlcE8q8lRq0PUzW4yyZN
         lLOoCFjIkUvOI1BeaC/JDJYXOjcTzsy3Gy0LhefiJSKa6RtFPUOzZq9AUkgvAbeof0Kl
         dcacp4dDoCp9bFwLua/xV/GwGPuCi+BoBQJbusoNCY62mQxuh9pZmvwFgMtXKvsXEEeh
         Ic/RjQnMrjTc3k0qkDsLvN7BhKkC0y/BEpfU1HrE6rIOhnCaFdgXw9VSeOC+AvjLCB9w
         /EqQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:from:to:cc:subject:message-id
         :mail-followup-to:mime-version:content-disposition:user-agent;
        bh=8GpH2/AsoDcjNS5c7qWj4v9T2WnCo4ViW9xFu4Gblkk=;
        b=Jox2VjqrxZCk6lS4satgCURpCsrQYLyVsT9mbF+mF0jCu0MUYRKy4/3JewY1VqxNyr
         DifVD48RHvdAX8yNEBWq2blf4YfkpW9cUoU3AoeyveKB/NrKZbE6hqdNXukNHhV708Qn
         dl1V9tLqhnzxn6lZtu4gqLfANHsoLjelBAtSxZgCLuCfKlq73SuL3om5QDBzhOe2gwG3
         cy7GwOOfhUIMTeRm37foUx7cd3Q7OKlIObT83kvNciB/mtSF7Ka6yZW129bWqHdD0KNv
         NQQf9xQfLE3CdwA0xJUYoPl4uU4wfXis4IG5ZTQHPiQkMKAsUm3/53fU+8YcoaJ004U/
         HwDQ==
X-Gm-Message-State: APjAAAVCj4vQS3HdVZJAnhV5DuSffobW5DnUDT7d+Eb4RF1SoI5NTe11
        1gzEArQslyW+MMZip+gVOwUjDmYe
X-Google-Smtp-Source: 
 APXvYqy2bXf3rk8cAahe8cm23+3EFqEve6ROdzipLqP4JFpEPDT18ekzSdylN6KKj0mZosnFuurBAQ==
X-Received: by 2002:a2e:824c:: with SMTP id j12mr19175822ljh.53.1559887404538;
        Thu, 06 Jun 2019 23:03:24 -0700 (PDT)
Received: from dnote ([31.173.87.118])
        by smtp.gmail.com with ESMTPSA id
 p10sm209390ljh.50.2019.06.06.23.03.23
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Thu, 06 Jun 2019 23:03:23 -0700 (PDT)
Date: Fri, 7 Jun 2019 09:03:21 +0300
From: Eugene Korenevsky <ekorenevsky@gmail.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>
Subject: [PATCH v5 2/3] kvm: vmx: segment limit check: use access length
Message-ID: <20190607060321.GA29109@dnote>
Mail-Followup-To: Eugene Korenevsky <ekorenevsky@gmail.com>,
        kvm@vger.kernel.org, Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
User-Agent: Mutt/1.12.0 (2019-05-25)
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

There is an imperfection in get_vmx_mem_address(): access length is
ignored when checking the limit. To fix this, pass access length as a
function argument. The value of access length is obvious since it is
used by callers after get_vmx_mem_address() call.

Signed-off-by: Eugene Korenevsky <ekorenevsky@gmail.com>
Reviewed-by: Sean Christopherson <sean.j.christopherson@intel.com>
---
Changes in v2 since v1: fixed logical bug (`len` argument was not used inside
get_vmx_mem_address() function); fixed the subject
Changes in v3 since v2: replace is_64_bit_mode() with is_long_mode() in
handle_vmwrite()
Changes in v4 since v3: revert previous change
Changes in v5 since v4: get_vmx_mem_address(): change type of `len` argument
from `int` to `unsigned int`

 arch/x86/kvm/vmx/nested.c | 29 +++++++++++++++++------------
 arch/x86/kvm/vmx/nested.h |  3 ++-
 arch/x86/kvm/vmx/vmx.c    |  3 ++-
 3 files changed, 21 insertions(+), 14 deletions(-)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index 1a51bff129a8..a2d744427d66 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -4008,7 +4008,8 @@ void nested_vmx_vmexit(struct kvm_vcpu *vcpu, u32 exit_reason,
  * #UD or #GP.
  */
 int get_vmx_mem_address(struct kvm_vcpu *vcpu, unsigned long exit_qualification,
-			u32 vmx_instruction_info, bool wr, gva_t *ret)
+			u32 vmx_instruction_info, bool wr,
+			unsigned int len, gva_t *ret)
 {
 	gva_t off;
 	bool exn;
@@ -4115,7 +4116,7 @@ int get_vmx_mem_address(struct kvm_vcpu *vcpu, unsigned long exit_qualification,
 		 */
 		if (!(s.base == 0 && s.limit == 0xffffffff &&
 		     ((s.type & 8) || !(s.type & 4))))
-			exn = exn || ((u64)off + sizeof(u64) - 1 > s.limit);
+			exn = exn || ((u64)off + len - 1 > s.limit);
 	}
 	if (exn) {
 		kvm_queue_exception_e(vcpu,
@@ -4134,7 +4135,8 @@ static int nested_vmx_get_vmptr(struct kvm_vcpu *vcpu, gpa_t *vmpointer)
 	struct x86_exception e;
 
 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
-			vmcs_read32(VMX_INSTRUCTION_INFO), false, &gva))
+				vmcs_read32(VMX_INSTRUCTION_INFO), false,
+				sizeof(*vmpointer), &gva))
 		return 1;
 
 	if (kvm_read_guest_virt(vcpu, gva, vmpointer, sizeof(*vmpointer), &e)) {
@@ -4386,6 +4388,7 @@ static int handle_vmread(struct kvm_vcpu *vcpu)
 	u64 field_value;
 	unsigned long exit_qualification = vmcs_readl(EXIT_QUALIFICATION);
 	u32 vmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);
+	unsigned int len;
 	gva_t gva = 0;
 	struct vmcs12 *vmcs12;
 
@@ -4423,12 +4426,12 @@ static int handle_vmread(struct kvm_vcpu *vcpu)
 		kvm_register_writel(vcpu, (((vmx_instruction_info) >> 3) & 0xf),
 			field_value);
 	} else {
+		len = is_long_mode(vcpu) ? 8 : 4;
 		if (get_vmx_mem_address(vcpu, exit_qualification,
-				vmx_instruction_info, true, &gva))
+				vmx_instruction_info, true, len, &gva))
 			return 1;
 		/* _system ok, nested_vmx_check_permission has verified cpl=0 */
-		kvm_write_guest_virt_system(vcpu, gva, &field_value,
-					    (is_long_mode(vcpu) ? 8 : 4), NULL);
+		kvm_write_guest_virt_system(vcpu, gva, &field_value, len, NULL);
 	}
 
 	return nested_vmx_succeed(vcpu);
@@ -4438,6 +4441,7 @@ static int handle_vmread(struct kvm_vcpu *vcpu)
 static int handle_vmwrite(struct kvm_vcpu *vcpu)
 {
 	unsigned long field;
+	unsigned int len;
 	gva_t gva;
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	unsigned long exit_qualification = vmcs_readl(EXIT_QUALIFICATION);
@@ -4463,11 +4467,11 @@ static int handle_vmwrite(struct kvm_vcpu *vcpu)
 		field_value = kvm_register_readl(vcpu,
 			(((vmx_instruction_info) >> 3) & 0xf));
 	else {
+		len = is_64_bit_mode(vcpu) ? 8 : 4;
 		if (get_vmx_mem_address(vcpu, exit_qualification,
-				vmx_instruction_info, false, &gva))
+				vmx_instruction_info, false, len, &gva))
 			return 1;
-		if (kvm_read_guest_virt(vcpu, gva, &field_value,
-					(is_64_bit_mode(vcpu) ? 8 : 4), &e)) {
+		if (kvm_read_guest_virt(vcpu, gva, &field_value, len, &e)) {
 			kvm_inject_page_fault(vcpu, &e);
 			return 1;
 		}
@@ -4615,7 +4619,8 @@ static int handle_vmptrst(struct kvm_vcpu *vcpu)
 	if (unlikely(to_vmx(vcpu)->nested.hv_evmcs))
 		return 1;
 
-	if (get_vmx_mem_address(vcpu, exit_qual, instr_info, true, &gva))
+	if (get_vmx_mem_address(vcpu, exit_qual, instr_info,
+				true, sizeof(gpa_t), &gva))
 		return 1;
 	/* *_system ok, nested_vmx_check_permission has verified cpl=0 */
 	if (kvm_write_guest_virt_system(vcpu, gva, (void *)&current_vmptr,
@@ -4661,7 +4666,7 @@ static int handle_invept(struct kvm_vcpu *vcpu)
 	 * operand is read even if it isn't needed (e.g., for type==global)
 	 */
 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
-			vmx_instruction_info, false, &gva))
+			vmx_instruction_info, false, sizeof(operand), &gva))
 		return 1;
 	if (kvm_read_guest_virt(vcpu, gva, &operand, sizeof(operand), &e)) {
 		kvm_inject_page_fault(vcpu, &e);
@@ -4723,7 +4728,7 @@ static int handle_invvpid(struct kvm_vcpu *vcpu)
 	 * operand is read even if it isn't needed (e.g., for type==global)
 	 */
 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
-			vmx_instruction_info, false, &gva))
+			vmx_instruction_info, false, sizeof(operand), &gva))
 		return 1;
 	if (kvm_read_guest_virt(vcpu, gva, &operand, sizeof(operand), &e)) {
 		kvm_inject_page_fault(vcpu, &e);
diff --git a/arch/x86/kvm/vmx/nested.h b/arch/x86/kvm/vmx/nested.h
index e847ff1019a2..a6cddb0a3564 100644
--- a/arch/x86/kvm/vmx/nested.h
+++ b/arch/x86/kvm/vmx/nested.h
@@ -21,7 +21,8 @@ void nested_sync_from_vmcs12(struct kvm_vcpu *vcpu);
 int vmx_set_vmx_msr(struct kvm_vcpu *vcpu, u32 msr_index, u64 data);
 int vmx_get_vmx_msr(struct nested_vmx_msrs *msrs, u32 msr_index, u64 *pdata);
 int get_vmx_mem_address(struct kvm_vcpu *vcpu, unsigned long exit_qualification,
-			u32 vmx_instruction_info, bool wr, gva_t *ret);
+			u32 vmx_instruction_info, bool wr,
+			unsigned int len, gva_t *ret);
 
 static inline struct vmcs12 *get_vmcs12(struct kvm_vcpu *vcpu)
 {
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index 1ac167614032..6ecf9e4de2f9 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -5342,7 +5342,8 @@ static int handle_invpcid(struct kvm_vcpu *vcpu)
 	 * is read even if it isn't needed (e.g., for type==all)
 	 */
 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
-				vmx_instruction_info, false, &gva))
+				vmx_instruction_info, false,
+				sizeof(operand), &gva))
 		return 1;
 
 	if (kvm_read_guest_virt(vcpu, gva, &operand, sizeof(operand), &e)) {

From patchwork Fri Jun  7 06:04:04 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Eugene Korenevsky <ekorenevsky@gmail.com>
X-Patchwork-Id: 10980797
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 3D7AB92A
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:04:11 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2951228AF3
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:04:11 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 1795728B04; Fri,  7 Jun 2019 06:04:11 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id BDB4628AF3
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  7 Jun 2019 06:04:10 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726721AbfFGGEJ (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Fri, 7 Jun 2019 02:04:09 -0400
Received: from mail-lj1-f196.google.com ([209.85.208.196]:39138 "EHLO
        mail-lj1-f196.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726575AbfFGGEJ (ORCPT <rfc822;kvm@vger.kernel.org>);
        Fri, 7 Jun 2019 02:04:09 -0400
Received: by mail-lj1-f196.google.com with SMTP id v18so658815ljh.6
        for <kvm@vger.kernel.org>; Thu, 06 Jun 2019 23:04:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=date:from:to:cc:subject:message-id:mail-followup-to:mime-version
         :content-disposition:user-agent;
        bh=MmvQ2pc0z+HvkwQjaWTsR4Wkccaoh3EGof+KVpniCvw=;
        b=rvHFQULJnd8YxI8kCLGBcUbRq6rkwpBmAd+HfE+5d7nTyIoyZIW3xcpkMzOE8HVuu0
         x1YwLmmaFPyd1pC9gIu0chl0TBjtA2OzRZJDp86q10EGVCUQN3uOj2gcE5RL/PsryXgG
         yv0E0vCs98N/TZ8j5kWDWdjA5s49XNKE+MvfwM6+E3HXcRN1gx0H8qRti7yiIUpbN1cP
         yrfLI6qjO/fES7BUhZFOqP0Q9d7rKtgewzTEiGXVmoIX2d5hGEoKQZLstnUpu/911nDl
         9CYiE6QooiwNj2qd0MizDFwg8NbAAzPrJbjmelCmmGwkOiQd7vjYKH0cIjTJA4RqoWZn
         YtlA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:from:to:cc:subject:message-id
         :mail-followup-to:mime-version:content-disposition:user-agent;
        bh=MmvQ2pc0z+HvkwQjaWTsR4Wkccaoh3EGof+KVpniCvw=;
        b=kp037J2E/uyLu9EikLlh3g1P9sYmRaRqHVa+A/mZ/hw/p2WQv8ChXxs7eMdY3Wjtqr
         f5BM7f8/a/ZW7Y9O64B2YRbtP1cNPSyH6mYXj8jr0CoE1AQTnFYzkgCqyGvsdaqBW4Dy
         gPhgBCWsS+Eja2C8wTtW6uh/z4AZd5054HOiW5Z50TGwFhC6JzOsvr03+DcIM1bzZOuL
         QWz7kxFN5Y2ERgUq2NWo/ookqPdTK00yS6rz1BKrO58Pk320PkvbE6cfzVlJgUU88JB6
         nCr0Woz1h5b17wfbVhORaoqybzoZvjMg+1FaTWLgcztybsamex33ga/I0y7HH5trwBcM
         69PA==
X-Gm-Message-State: APjAAAVGccWTcEUkCFx6sjlPUCDNiG6hquP5qposxIETbhUa3gPd87CZ
        BkMgdmTjpNUVZMB5o/X0Oa6+/w03
X-Google-Smtp-Source: 
 APXvYqyfia+2LCkeLvpHo9LJed30gn5dcsB+BT/DpVOfgn5yBMJGI/HW3+6IuHqua1HoeRKn/asrew==
X-Received: by 2002:a2e:980e:: with SMTP id a14mr16178566ljj.60.1559887446836;
        Thu, 06 Jun 2019 23:04:06 -0700 (PDT)
Received: from dnote ([31.173.87.118])
        by smtp.gmail.com with ESMTPSA id
 d65sm235292lfd.72.2019.06.06.23.04.05
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Thu, 06 Jun 2019 23:04:06 -0700 (PDT)
Date: Fri, 7 Jun 2019 09:04:04 +0300
From: Eugene Korenevsky <ekorenevsky@gmail.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>
Subject: [PATCH v5 3/3] kvm: vmx: handle_vmwrite: avoid checking for
 compatibility mode
Message-ID: <20190607060404.GA29127@dnote>
Mail-Followup-To: Eugene Korenevsky <ekorenevsky@gmail.com>,
        kvm@vger.kernel.org, Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
User-Agent: Mutt/1.12.0 (2019-05-25)
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

handle_vmwrite() should use is_long_mode() instead of is_64_bit_mode()
because VMWRITE opcode is invalid in compatibility mode and there is no
reason for extra checking CS.L.

Signed-off-by: Eugene Korenevsky <ekorenevsky@gmail.com>
Reviewed-by: Sean Christopherson <sean.j.christopherson@intel.com>
---
 arch/x86/kvm/vmx/nested.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index a2d744427d66..b39fc075aead 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -4467,7 +4467,7 @@ static int handle_vmwrite(struct kvm_vcpu *vcpu)
 		field_value = kvm_register_readl(vcpu,
 			(((vmx_instruction_info) >> 3) & 0xf));
 	else {
-		len = is_64_bit_mode(vcpu) ? 8 : 4;
+		len = is_long_mode(vcpu) ? 8 : 4;
 		if (get_vmx_mem_address(vcpu, exit_qualification,
 				vmx_instruction_info, false, len, &gva))
 			return 1;

From patchwork Sat Sep 22 01:56:38 2018
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Wei Yang <richard.weiyang@gmail.com>
X-Patchwork-Id: 10611313
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 662945A4
	for <patchwork-kvm@patchwork.kernel.org>;
 Sat, 22 Sep 2018 01:57:14 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3F5CA2D87D
	for <patchwork-kvm@patchwork.kernel.org>;
 Sat, 22 Sep 2018 01:57:14 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 19A3C2D8CC; Sat, 22 Sep 2018 01:57:14 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7FC7D2D87D
	for <patchwork-kvm@patchwork.kernel.org>;
 Sat, 22 Sep 2018 01:57:13 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2391585AbeIVHsl (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Sat, 22 Sep 2018 03:48:41 -0400
Received: from mail-pl1-f195.google.com ([209.85.214.195]:42420 "EHLO
        mail-pl1-f195.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1728318AbeIVHsl (ORCPT <rfc822;kvm@vger.kernel.org>);
        Sat, 22 Sep 2018 03:48:41 -0400
Received: by mail-pl1-f195.google.com with SMTP id x20-v6so1151230pln.9
        for <kvm@vger.kernel.org>; Fri, 21 Sep 2018 18:57:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=from:to:cc:subject:date:message-id;
        bh=638VIXb1UKRqS/wbY7hd8otq4q9GPrvOwAaDRr2R9SQ=;
        b=epRIaAJ2d5or3F9v4IQD+GIMs4726KLZY1QWw9LJk3OfBs6fPDWab83xZFUuBM75mE
         FJFlULbrs/qMRl5qqLRVEhR87nDygoc9NUBIG9fYJZhyY68pzNqCgXIZnouPxfw8kEvW
         q7njNXe3BXm2SUzRTE8Faec86HbZ3jQZ6PLZVZnXgayvct4OvxrMZomRubLUKzzBkpPQ
         8dhweXcfdKb3zo8LC+XOz7XxbgBdy+G6eBA5T4iYZgTxCD6mLbXXUWwH7hwCuXd4Lo7e
         kIT77VWlwzjDw4UAvNaJa9rMMJeRoLnAYHUk00IoDGbB9xnAOlyZsxBnxeM93dAqooSP
         bxuQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id;
        bh=638VIXb1UKRqS/wbY7hd8otq4q9GPrvOwAaDRr2R9SQ=;
        b=WVKBQT/j4ZmdZr3D3QdBH2rHrAeEqlYXy7kd1WKUMDvwNZL9QQKxnBTm/YvTcLDKqp
         nML6V5m70tffrndKcoiDgUTfBi+wA9Ro0C2kqOL7F3fOEXDXKgakaAvJqP8ktcl/Mkm0
         EgxDzL3V7xBcEH+M03y2seDTjv0AXVw3xf0th6JJFzQ5Q6ul4OW6XeIiqaP8d3YCROlx
         b3j0PcRk0vkfCehtyfeXAaBctJE15seKN6HPsSUChrIZwQhT5H4t0X/ypZ65oi+2MDTl
         TXTg6aQx4wT68JbFRdR/lqVKudiQHiz122MgrDGDexER0UbcjuTOKIDSu/1vjLDKSnHZ
         HzCA==
X-Gm-Message-State: ABuFfogfa06z6nC8jw5qsb+/7SSEWiGPf0v8JzkVZtG/6+jeqIg9HRjQ
        8IwE//O14RiGe/v8hO8KBDI=
X-Google-Smtp-Source: 
 ACcGV62zt4mv3NKHbsb5kn2zV6dTxkh19M+MlzEa0M1atOAKs1urfZHaM3BAgisk+RzZK6jLDTdMZw==
X-Received: by 2002:a17:902:6a8a:: with SMTP id
 n10-v6mr344331plk.288.1537581425881;
        Fri, 21 Sep 2018 18:57:05 -0700 (PDT)
Received: from localhost ([185.92.221.13])
        by smtp.gmail.com with ESMTPSA id
 132-v6sm1209321pgh.67.2018.09.21.18.57.02
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 21 Sep 2018 18:57:04 -0700 (PDT)
From: Wei Yang <richard.weiyang@gmail.com>
To: pbonzini@redhat.com, rkrcmar@redhat.com, tglx@linutronix.de
Cc: x86@kernel.org, kvm@vger.kernel.org,
        Wei Yang <richard.weiyang@gmail.com>
Subject: [PATCH 1/2] KVM: x86: replace KVM_PAGES_PER_HPAGE with
 KVM_HPAGE_GFN_SIZE
Date: Sat, 22 Sep 2018 09:56:38 +0800
Message-Id: <20180922015639.12666-1-richard.weiyang@gmail.com>
X-Mailer: git-send-email 2.15.1
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

KVM_PAGES_PER_HPAGE is got by left shift (KVM_HPAGE_GFN_SHIFT + PAGE_SHIFT)
and then divide by PAGE_SIZE, which could be simplified by just left shift
KVM_HPAGE_GFN_SHIFT.

At the same time, in almost 40% places where KVM_PAGES_PER_HPAGE is used,
pfn mask is actually what it needs instead of the number of pages.

This patch replaces KVM_PAGES_PER_HPAGE with KVM_HPAGE_GFN_SIZE and
introduces KVM_HPAGE_GFN_MASK to make it a little bit easy to read.

Signed-off-by: Wei Yang <richard.weiyang@gmail.com>
---
 arch/x86/include/asm/kvm_host.h |  3 ++-
 arch/x86/kvm/mmu.c              | 10 +++++-----
 arch/x86/kvm/paging_tmpl.h      |  6 +++---
 arch/x86/kvm/x86.c              |  6 +++---
 4 files changed, 13 insertions(+), 12 deletions(-)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index f1a4e520ef5c..c5e7bb811b1e 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -104,10 +104,11 @@
 /* KVM Hugepage definitions for x86 */
 #define KVM_NR_PAGE_SIZES	3
 #define KVM_HPAGE_GFN_SHIFT(x)	(((x) - 1) * 9)
+#define KVM_HPAGE_GFN_SIZE(x)	(1UL << KVM_HPAGE_GFN_SHIFT(x))
+#define KVM_HPAGE_GFN_MASK(x)	(~(KVM_HPAGE_GFN_SIZE(x) - 1))
 #define KVM_HPAGE_SHIFT(x)	(PAGE_SHIFT + KVM_HPAGE_GFN_SHIFT(x))
 #define KVM_HPAGE_SIZE(x)	(1UL << KVM_HPAGE_SHIFT(x))
 #define KVM_HPAGE_MASK(x)	(~(KVM_HPAGE_SIZE(x) - 1))
-#define KVM_PAGES_PER_HPAGE(x)	(KVM_HPAGE_SIZE(x) / PAGE_SIZE)
 
 static inline gfn_t gfn_to_index(gfn_t gfn, gfn_t base_gfn, int level)
 {
diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c
index 0caaaa25e88b..897614414311 100644
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -3170,7 +3170,7 @@ static void transparent_hugepage_adjust(struct kvm_vcpu *vcpu,
 		 * head.
 		 */
 		*levelp = level = PT_DIRECTORY_LEVEL;
-		mask = KVM_PAGES_PER_HPAGE(level) - 1;
+		mask = KVM_HPAGE_GFN_SIZE(level) - 1;
 		VM_BUG_ON((gfn & mask) != (pfn & mask));
 		if (pfn & mask) {
 			gfn &= ~mask;
@@ -3416,7 +3416,7 @@ static int nonpaging_map(struct kvm_vcpu *vcpu, gva_t v, u32 error_code,
 		if (level > PT_DIRECTORY_LEVEL)
 			level = PT_DIRECTORY_LEVEL;
 
-		gfn &= ~(KVM_PAGES_PER_HPAGE(level) - 1);
+		gfn &= KVM_HPAGE_GFN_MASK(level);
 	}
 
 	if (fast_page_fault(vcpu, v, level, error_code))
@@ -4018,9 +4018,9 @@ EXPORT_SYMBOL_GPL(kvm_handle_page_fault);
 static bool
 check_hugepage_cache_consistency(struct kvm_vcpu *vcpu, gfn_t gfn, int level)
 {
-	int page_num = KVM_PAGES_PER_HPAGE(level);
+	int page_num = KVM_HPAGE_GFN_SIZE(level);
 
-	gfn &= ~(page_num - 1);
+	gfn &= KVM_HPAGE_GFN_MASK(level);
 
 	return kvm_mtrr_check_gfn_range_consistency(vcpu, gfn, page_num);
 }
@@ -4053,7 +4053,7 @@ static int tdp_page_fault(struct kvm_vcpu *vcpu, gva_t gpa, u32 error_code,
 		if (level > PT_DIRECTORY_LEVEL &&
 		    !check_hugepage_cache_consistency(vcpu, gfn, level))
 			level = PT_DIRECTORY_LEVEL;
-		gfn &= ~(KVM_PAGES_PER_HPAGE(level) - 1);
+		gfn &= KVM_HPAGE_GFN_MASK(level);
 	}
 
 	if (fast_page_fault(vcpu, gpa, level, error_code))
diff --git a/arch/x86/kvm/paging_tmpl.h b/arch/x86/kvm/paging_tmpl.h
index 14ffd973df54..c8a242715cbb 100644
--- a/arch/x86/kvm/paging_tmpl.h
+++ b/arch/x86/kvm/paging_tmpl.h
@@ -658,7 +658,7 @@ static int FNAME(fetch)(struct kvm_vcpu *vcpu, gva_t addr,
 		if (is_shadow_present_pte(*it.sptep))
 			continue;
 
-		direct_gfn = gw->gfn & ~(KVM_PAGES_PER_HPAGE(it.level) - 1);
+		direct_gfn = gw->gfn & KVM_HPAGE_GFN_MASK(it.level);
 
 		sp = kvm_mmu_get_page(vcpu, direct_gfn, addr, it.level-1,
 				      true, direct_access);
@@ -700,7 +700,7 @@ FNAME(is_self_change_mapping)(struct kvm_vcpu *vcpu,
 			      bool *write_fault_to_shadow_pgtable)
 {
 	int level;
-	gfn_t mask = ~(KVM_PAGES_PER_HPAGE(walker->level) - 1);
+	gfn_t mask = KVM_HPAGE_GFN_MASK(walker->level);
 	bool self_changed = false;
 
 	if (!(walker->pte_access & ACC_WRITE_MASK ||
@@ -786,7 +786,7 @@ static int FNAME(page_fault)(struct kvm_vcpu *vcpu, gva_t addr, u32 error_code,
 		level = mapping_level(vcpu, walker.gfn, &force_pt_level);
 		if (likely(!force_pt_level)) {
 			level = min(walker.level, level);
-			walker.gfn = walker.gfn & ~(KVM_PAGES_PER_HPAGE(level) - 1);
+			walker.gfn = walker.gfn & KVM_HPAGE_GFN_MASK(level);
 		}
 	} else
 		force_pt_level = true;
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index f7dff0457846..70b4e5e74f7d 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -9021,9 +9021,9 @@ int kvm_arch_create_memslot(struct kvm *kvm, struct kvm_memory_slot *slot,
 
 		slot->arch.lpage_info[i - 1] = linfo;
 
-		if (slot->base_gfn & (KVM_PAGES_PER_HPAGE(level) - 1))
+		if (slot->base_gfn & (KVM_HPAGE_GFN_SIZE(level) - 1))
 			linfo[0].disallow_lpage = 1;
-		if ((slot->base_gfn + npages) & (KVM_PAGES_PER_HPAGE(level) - 1))
+		if ((slot->base_gfn + npages) & (KVM_HPAGE_GFN_SIZE(level) - 1))
 			linfo[lpages - 1].disallow_lpage = 1;
 		ugfn = slot->userspace_addr >> PAGE_SHIFT;
 		/*
@@ -9031,7 +9031,7 @@ int kvm_arch_create_memslot(struct kvm *kvm, struct kvm_memory_slot *slot,
 		 * other, or if explicitly asked to, disable large page
 		 * support for this slot
 		 */
-		if ((slot->base_gfn ^ ugfn) & (KVM_PAGES_PER_HPAGE(level) - 1) ||
+		if ((slot->base_gfn ^ ugfn) & (KVM_HPAGE_GFN_SIZE(level) - 1) ||
 		    !kvm_largepages_enabled()) {
 			unsigned long j;
 

From patchwork Sat Sep 22 01:56:39 2018
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Wei Yang <richard.weiyang@gmail.com>
X-Patchwork-Id: 10611315
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 05F0D15A6
	for <patchwork-kvm@patchwork.kernel.org>;
 Sat, 22 Sep 2018 01:57:23 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E9AB12D87D
	for <patchwork-kvm@patchwork.kernel.org>;
 Sat, 22 Sep 2018 01:57:22 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id DCECA2D8CC; Sat, 22 Sep 2018 01:57:22 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8CCDE2D87D
	for <patchwork-kvm@patchwork.kernel.org>;
 Sat, 22 Sep 2018 01:57:22 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2391701AbeIVHsw (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Sat, 22 Sep 2018 03:48:52 -0400
Received: from mail-pg1-f196.google.com ([209.85.215.196]:33378 "EHLO
        mail-pg1-f196.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S2391689AbeIVHsv (ORCPT <rfc822;kvm@vger.kernel.org>);
        Sat, 22 Sep 2018 03:48:51 -0400
Received: by mail-pg1-f196.google.com with SMTP id y18-v6so3504479pge.0
        for <kvm@vger.kernel.org>; Fri, 21 Sep 2018 18:57:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=n90OkVrWe3mbyEL4AaOQA8+x5U4ua8uiP3Qk/GCt1+I=;
        b=K3MC4LOeSfBkozDgI8eHAeCoEr0/lU0h+RpcbI8UyrAxmEeUURUbaZp6Ave2knC07e
         RrY///M4T9PR0WelKGP1yl0lFpWWIOvbKet9/xv5FMjrE4/igGOM331Up/HOJPL7enL9
         C8hhbIGrhpXKkZ8sOyPuya8MyepYnYsftapEkxv5o/T3uHuCD53kPe5lOoTmnhxF0r+n
         pVvjCaNh+/TMFg95iNvyfh+yDja3Wn5O5tc77BETfIlhH1ssQZNl18c2dLhIeMHVXGKB
         mjCrlXf4rKY2Tt8xrl7OsX7vP5sBYYkQ0CMgEMuzyqMulwCYdR0cBuSIi4WlWtYCOEQh
         CJag==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
         :references;
        bh=n90OkVrWe3mbyEL4AaOQA8+x5U4ua8uiP3Qk/GCt1+I=;
        b=j3f9qlmmwIBvFvFKL5Ib+WqtoqV2BxsxVR5lAXYaQjubx1Dr8hR6xASu3JiTF5j0L+
         AttIxsj0SYd9vMUYvaKZcRMr2j/YGoEwp5k5XAIb0g1JASgF7+zbioD//RuySIWaTb3Q
         4vqFx0PqqMlqmksQHSKntJJWbwPFmv2Rrp+/QcQxHQNWK3ZfTIylau877EWnyV2ZNR9f
         ac6dFKsApQK6b//J8KW3bCbpyJyfxlTrf7gTPSog7Kf/HntSIxMgBtsQEG55mAL52nEG
         tEuPs5qTHYRPdngU83YDV1rgwgVTUorsXdAivYhoS1sfoj6c0873DrpeKrho+KVz2o0f
         cXFw==
X-Gm-Message-State: ABuFfoiI+cXu3NE/Dm9dti5GBHbOnaK4RxwvhNm3K7Z9+OyAWuC/IOgo
        k+lToAP9Wn6BIbD6tUIPfAI=
X-Google-Smtp-Source: 
 ACcGV62Z8hxIFjxgPsDQMO3CAqvtvqzcO+Tkms/JvWddyM7y79ampulg9HaIi3y6kCYAlYo/j8272w==
X-Received: by 2002:a63:ef4f:: with SMTP id
 c15-v6mr321517pgk.368.1537581436869;
        Fri, 21 Sep 2018 18:57:16 -0700 (PDT)
Received: from localhost ([185.92.221.13])
        by smtp.gmail.com with ESMTPSA id
 d7-v6sm19174207pfg.1.2018.09.21.18.57.14
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 21 Sep 2018 18:57:16 -0700 (PDT)
From: Wei Yang <richard.weiyang@gmail.com>
To: pbonzini@redhat.com, rkrcmar@redhat.com, tglx@linutronix.de
Cc: x86@kernel.org, kvm@vger.kernel.org,
        Wei Yang <richard.weiyang@gmail.com>
Subject: [PATCH 2/2] KVM: x86: remove duplicate cr0 set in vmx_vcpu_reset()
Date: Sat, 22 Sep 2018 09:56:39 +0800
Message-Id: <20180922015639.12666-2-richard.weiyang@gmail.com>
X-Mailer: git-send-email 2.15.1
In-Reply-To: <20180922015639.12666-1-richard.weiyang@gmail.com>
References: <20180922015639.12666-1-richard.weiyang@gmail.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

vmx->vcpu.arch.cr0 will be set in vmx_set_cr0().

This patch removes duplicate cr0 set in vmx_vcpu_reset().

Signed-off-by: Wei Yang <richard.weiyang@gmail.com>
Reviewed-by: Krish Sadhukhan <krish.sadhukhan@oracle.com>
---
 arch/x86/kvm/vmx.c | 1 -
 1 file changed, 1 deletion(-)

diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c
index 1519f030fd73..b1e1d63a4970 100644
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@ -6734,7 +6734,6 @@ static void vmx_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 		vmcs_write16(VIRTUAL_PROCESSOR_ID, vmx->vpid);
 
 	cr0 = X86_CR0_NW | X86_CR0_CD | X86_CR0_ET;
-	vmx->vcpu.arch.cr0 = cr0;
 	vmx_set_cr0(vcpu, cr0); /* enter rmode */
 	vmx_set_cr4(vcpu, 0);
 	vmx_set_efer(vcpu, 0);

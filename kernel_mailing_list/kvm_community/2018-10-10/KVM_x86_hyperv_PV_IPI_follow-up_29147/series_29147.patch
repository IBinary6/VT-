From patchwork Wed Oct 10 15:14:37 2018
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Vitaly Kuznetsov <vkuznets@redhat.com>
X-Patchwork-Id: 10634749
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 19B8A679F
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 10 Oct 2018 15:14:47 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C9FFF287AC
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 10 Oct 2018 15:14:44 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id BE25228889; Wed, 10 Oct 2018 15:14:44 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.9 required=2.0 tests=BAYES_00,MAILING_LIST_MULTI,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1F26A287AC
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 10 Oct 2018 15:14:44 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726873AbeJJWhU (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Wed, 10 Oct 2018 18:37:20 -0400
Received: from mx1.redhat.com ([209.132.183.28]:52290 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726647AbeJJWhT (ORCPT <rfc822;kvm@vger.kernel.org>);
        Wed, 10 Oct 2018 18:37:19 -0400
Received: from smtp.corp.redhat.com (int-mx01.intmail.prod.int.phx2.redhat.com
 [10.5.11.11])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id 8124530B8F9E;
        Wed, 10 Oct 2018 15:14:42 +0000 (UTC)
Received: from vitty.brq.redhat.com (unknown [10.43.2.58])
        by smtp.corp.redhat.com (Postfix) with ESMTP id 531D883EBE;
        Wed, 10 Oct 2018 15:14:41 +0000 (UTC)
From: Vitaly Kuznetsov <vkuznets@redhat.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
 =?utf-8?b?UmFkaW0gS3LEjW3DocWZ?= <rkrcmar@redhat.com>,
 Roman Kagan <rkagan@virtuozzo.com>
Subject: [PATCH v2 1/2] KVM: x86: hyperv: fix 'tlb_lush' typo
Date: Wed, 10 Oct 2018 17:14:37 +0200
Message-Id: <20181010151438.19963-2-vkuznets@redhat.com>
In-Reply-To: <20181010151438.19963-1-vkuznets@redhat.com>
References: <20181010151438.19963-1-vkuznets@redhat.com>
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.11
X-Greylist: Sender IP whitelisted,
 not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.49]);
 Wed, 10 Oct 2018 15:14:42 +0000 (UTC)
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

Regardless of whether your TLB is lush or not it still needs flushing.

Reported-by: Roman Kagan <rkagan@virtuozzo.com>
Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Reviewed-by: Roman Kagan <rkagan@virtuozzo.com>
---
 arch/x86/include/asm/kvm_host.h | 2 +-
 arch/x86/kvm/hyperv.c           | 6 +++---
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index d81f536d024a..901572b4f6f7 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -499,7 +499,7 @@ struct kvm_vcpu_hv {
 	struct kvm_hyperv_exit exit;
 	struct kvm_vcpu_hv_stimer stimer[HV_SYNIC_STIMER_COUNT];
 	DECLARE_BITMAP(stimer_pending_bitmap, HV_SYNIC_STIMER_COUNT);
-	cpumask_t tlb_lush;
+	cpumask_t tlb_flush;
 };
 
 struct kvm_vcpu_arch {
diff --git a/arch/x86/kvm/hyperv.c b/arch/x86/kvm/hyperv.c
index bad4bffdc8b9..f1ae1777519c 100644
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@ -1354,12 +1354,12 @@ static u64 kvm_hv_flush_tlb(struct kvm_vcpu *current_vcpu, u64 ingpa,
 	 * vcpu->arch.cr3 may not be up-to-date for running vCPUs so we can't
 	 * analyze it here, flush TLB regardless of the specified address space.
 	 */
-	cpumask_clear(&hv_vcpu->tlb_lush);
+	cpumask_clear(&hv_vcpu->tlb_flush);
 
 	if (all_cpus) {
 		kvm_make_vcpus_request_mask(kvm,
 				    KVM_REQ_TLB_FLUSH | KVM_REQUEST_NO_WAKEUP,
-				    NULL, &hv_vcpu->tlb_lush);
+				    NULL, &hv_vcpu->tlb_flush);
 		goto ret_success;
 	}
 
@@ -1397,7 +1397,7 @@ static u64 kvm_hv_flush_tlb(struct kvm_vcpu *current_vcpu, u64 ingpa,
 flush_request:
 	kvm_make_vcpus_request_mask(kvm,
 				    KVM_REQ_TLB_FLUSH | KVM_REQUEST_NO_WAKEUP,
-				    vcpu_bitmap, &hv_vcpu->tlb_lush);
+				    vcpu_bitmap, &hv_vcpu->tlb_flush);
 
 ret_success:
 	/* We always do full TLB flush, set rep_done = rep_cnt. */

From patchwork Wed Oct 10 15:14:38 2018
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Vitaly Kuznetsov <vkuznets@redhat.com>
X-Patchwork-Id: 10634751
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id B572669B1
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 10 Oct 2018 15:15:00 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 16FED1FFF9
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 10 Oct 2018 15:14:47 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 0B41728889; Wed, 10 Oct 2018 15:14:47 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.9 required=2.0 tests=BAYES_00,MAILING_LIST_MULTI,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 593A01FFF9
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 10 Oct 2018 15:14:46 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726903AbeJJWhW (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Wed, 10 Oct 2018 18:37:22 -0400
Received: from mx1.redhat.com ([209.132.183.28]:55116 "EHLO mx1.redhat.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726647AbeJJWhV (ORCPT <rfc822;kvm@vger.kernel.org>);
        Wed, 10 Oct 2018 18:37:21 -0400
Received: from smtp.corp.redhat.com (int-mx01.intmail.prod.int.phx2.redhat.com
 [10.5.11.11])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mx1.redhat.com (Postfix) with ESMTPS id 280A53AA14;
        Wed, 10 Oct 2018 15:14:44 +0000 (UTC)
Received: from vitty.brq.redhat.com (unknown [10.43.2.58])
        by smtp.corp.redhat.com (Postfix) with ESMTP id C31FA83EB9;
        Wed, 10 Oct 2018 15:14:42 +0000 (UTC)
From: Vitaly Kuznetsov <vkuznets@redhat.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
 =?utf-8?b?UmFkaW0gS3LEjW3DocWZ?= <rkrcmar@redhat.com>,
 Roman Kagan <rkagan@virtuozzo.com>
Subject: [PATCH v2 2/2] KVM: x86: hyperv: optimize sparse VP set processing
Date: Wed, 10 Oct 2018 17:14:38 +0200
Message-Id: <20181010151438.19963-3-vkuznets@redhat.com>
In-Reply-To: <20181010151438.19963-1-vkuznets@redhat.com>
References: <20181010151438.19963-1-vkuznets@redhat.com>
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.11
X-Greylist: Sender IP whitelisted,
 not delayed by milter-greylist-4.5.16 (mx1.redhat.com [10.5.110.38]);
 Wed, 10 Oct 2018 15:14:44 +0000 (UTC)
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

Rewrite kvm_hv_flush_tlb()/send_ipi_vcpus_mask() making them cleaner and
somewhat more optimal.

hv_vcpu_in_sparse_set() is converted to sparse_set_to_vcpu_mask()
which copies sparse banks u64-at-a-time and then, depending on the
num_mismatched_vp_indexes value, returns immediately or does
vp index to vcpu index conversion by walking all vCPUs.

To support the change and make kvm_hv_send_ipi() look similar to
kvm_hv_flush_tlb() send_ipi_vcpus_mask() is introduced.

Suggested-by: Roman Kagan <rkagan@virtuozzo.com>
Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Reviewed-by: Roman Kagan <rkagan@virtuozzo.com>
---
 arch/x86/kvm/hyperv.c | 163 +++++++++++++++++-------------------------
 1 file changed, 65 insertions(+), 98 deletions(-)

diff --git a/arch/x86/kvm/hyperv.c b/arch/x86/kvm/hyperv.c
index f1ae1777519c..5e74ba6a1e7a 100644
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@ -36,6 +36,8 @@
 
 #include "trace.h"
 
+#define KVM_HV_MAX_SPARSE_VCPU_SET_BITS DIV_ROUND_UP(KVM_MAX_VCPUS, 64)
+
 static inline u64 synic_read_sint(struct kvm_vcpu_hv_synic *synic, int sint)
 {
 	return atomic64_read(&synic->sint[sint]);
@@ -1277,37 +1279,47 @@ int kvm_hv_get_msr_common(struct kvm_vcpu *vcpu, u32 msr, u64 *pdata, bool host)
 		return kvm_hv_get_msr(vcpu, msr, pdata, host);
 }
 
-static __always_inline bool hv_vcpu_in_sparse_set(struct kvm_vcpu_hv *hv_vcpu,
-						  u64 sparse_banks[],
-						  u64 valid_bank_mask)
+static __always_inline unsigned long *sparse_set_to_vcpu_mask(
+	struct kvm *kvm, u64 *sparse_banks, u64 valid_bank_mask,
+	u64 *vp_bitmap, unsigned long *vcpu_bitmap)
 {
-	int bank = hv_vcpu->vp_index / 64, sbank;
-
-	if (bank >= 64)
-		return false;
+	struct kvm_hv *hv = &kvm->arch.hyperv;
+	struct kvm_vcpu *vcpu;
+	int i, bank, sbank = 0;
 
-	if (!(valid_bank_mask & BIT_ULL(bank)))
-		return false;
+	memset(vp_bitmap, 0,
+	       KVM_HV_MAX_SPARSE_VCPU_SET_BITS * sizeof(*vp_bitmap));
+	for_each_set_bit(bank, (unsigned long *)&valid_bank_mask,
+			 KVM_HV_MAX_SPARSE_VCPU_SET_BITS)
+		vp_bitmap[bank] = sparse_banks[sbank++];
 
-	/* Sparse bank number equals to the number of set bits before it */
-	sbank = bitmap_weight((unsigned long *)&valid_bank_mask, bank);
+	if (likely(!atomic_read(&hv->num_mismatched_vp_indexes))) {
+		/* for all vcpus vp_index == vcpu_idx */
+		return (unsigned long *)vp_bitmap;
+	}
 
-	return !!(sparse_banks[sbank] & BIT_ULL(hv_vcpu->vp_index % 64));
+	bitmap_zero(vcpu_bitmap, KVM_MAX_VCPUS);
+	kvm_for_each_vcpu(i, vcpu, kvm) {
+		if (test_bit(vcpu_to_hv_vcpu(vcpu)->vp_index,
+			     (unsigned long *)vp_bitmap))
+			__set_bit(i, vcpu_bitmap);
+	}
+	return vcpu_bitmap;
 }
 
 static u64 kvm_hv_flush_tlb(struct kvm_vcpu *current_vcpu, u64 ingpa,
 			    u16 rep_cnt, bool ex)
 {
 	struct kvm *kvm = current_vcpu->kvm;
-	struct kvm_hv *hv = &kvm->arch.hyperv;
 	struct kvm_vcpu_hv *hv_vcpu = &current_vcpu->arch.hyperv;
 	struct hv_tlb_flush_ex flush_ex;
 	struct hv_tlb_flush flush;
-	struct kvm_vcpu *vcpu;
-	unsigned long vcpu_bitmap[BITS_TO_LONGS(KVM_MAX_VCPUS)] = {0};
+	u64 vp_bitmap[KVM_HV_MAX_SPARSE_VCPU_SET_BITS];
+	DECLARE_BITMAP(vcpu_bitmap, KVM_MAX_VCPUS);
+	unsigned long *vcpu_mask;
 	u64 valid_bank_mask;
 	u64 sparse_banks[64];
-	int sparse_banks_len, i, bank, sbank;
+	int sparse_banks_len;
 	bool all_cpus;
 
 	if (!ex) {
@@ -1350,54 +1362,19 @@ static u64 kvm_hv_flush_tlb(struct kvm_vcpu *current_vcpu, u64 ingpa,
 			return HV_STATUS_INVALID_HYPERCALL_INPUT;
 	}
 
-	/*
-	 * vcpu->arch.cr3 may not be up-to-date for running vCPUs so we can't
-	 * analyze it here, flush TLB regardless of the specified address space.
-	 */
 	cpumask_clear(&hv_vcpu->tlb_flush);
 
-	if (all_cpus) {
-		kvm_make_vcpus_request_mask(kvm,
-				    KVM_REQ_TLB_FLUSH | KVM_REQUEST_NO_WAKEUP,
-				    NULL, &hv_vcpu->tlb_flush);
-		goto ret_success;
-	}
-
-	if (atomic_read(&hv->num_mismatched_vp_indexes)) {
-		kvm_for_each_vcpu(i, vcpu, kvm) {
-			if (hv_vcpu_in_sparse_set(&vcpu->arch.hyperv,
-						  sparse_banks,
-						  valid_bank_mask))
-				__set_bit(i, vcpu_bitmap);
-		}
-		goto flush_request;
-	}
+	vcpu_mask = all_cpus ? NULL :
+		sparse_set_to_vcpu_mask(kvm, sparse_banks, valid_bank_mask,
+					vp_bitmap, vcpu_bitmap);
 
 	/*
-	 * num_mismatched_vp_indexes is zero so every vcpu has
-	 * vp_index == vcpu_idx.
+	 * vcpu->arch.cr3 may not be up-to-date for running vCPUs so we can't
+	 * analyze it here, flush TLB regardless of the specified address space.
 	 */
-	sbank = 0;
-	for_each_set_bit(bank, (unsigned long *)&valid_bank_mask,
-			 BITS_PER_LONG) {
-		for_each_set_bit(i,
-				 (unsigned long *)&sparse_banks[sbank],
-				 BITS_PER_LONG) {
-			u32 vp_index = bank * 64 + i;
-
-			/* A non-existent vCPU was specified */
-			if (vp_index >= KVM_MAX_VCPUS)
-				return HV_STATUS_INVALID_HYPERCALL_INPUT;
-
-			__set_bit(vp_index, vcpu_bitmap);
-		}
-		sbank++;
-	}
-
-flush_request:
 	kvm_make_vcpus_request_mask(kvm,
 				    KVM_REQ_TLB_FLUSH | KVM_REQUEST_NO_WAKEUP,
-				    vcpu_bitmap, &hv_vcpu->tlb_flush);
+				    vcpu_mask, &hv_vcpu->tlb_flush);
 
 ret_success:
 	/* We always do full TLB flush, set rep_done = rep_cnt. */
@@ -1405,18 +1382,36 @@ static u64 kvm_hv_flush_tlb(struct kvm_vcpu *current_vcpu, u64 ingpa,
 		((u64)rep_cnt << HV_HYPERCALL_REP_COMP_OFFSET);
 }
 
+static void send_ipi_vcpus_mask(struct kvm *kvm, u32 vector,
+				unsigned long *vcpu_bitmap)
+{
+	struct kvm_lapic_irq irq = {.delivery_mode = APIC_DM_FIXED,
+				    .vector = vector};
+	struct kvm_vcpu *vcpu;
+	int i;
+
+	kvm_for_each_vcpu(i, vcpu, kvm) {
+		if (vcpu_bitmap && !test_bit(i, vcpu_bitmap))
+			continue;
+
+		/* We fail only when APIC is disabled */
+		kvm_apic_set_irq(vcpu, &irq, NULL);
+	}
+}
+
 static u64 kvm_hv_send_ipi(struct kvm_vcpu *current_vcpu, u64 ingpa, u64 outgpa,
 			   bool ex, bool fast)
 {
 	struct kvm *kvm = current_vcpu->kvm;
-	struct kvm_hv *hv = &kvm->arch.hyperv;
 	struct hv_send_ipi_ex send_ipi_ex;
 	struct hv_send_ipi send_ipi;
-	struct kvm_vcpu *vcpu;
+	u64 vp_bitmap[KVM_HV_MAX_SPARSE_VCPU_SET_BITS];
+	DECLARE_BITMAP(vcpu_bitmap, KVM_MAX_VCPUS);
+	unsigned long *vcpu_mask;
 	unsigned long valid_bank_mask;
 	u64 sparse_banks[64];
-	int sparse_banks_len, bank, i, sbank;
-	struct kvm_lapic_irq irq = {.delivery_mode = APIC_DM_FIXED};
+	int sparse_banks_len;
+	u32 vector;
 	bool all_cpus;
 
 	if (!ex) {
@@ -1425,18 +1420,18 @@ static u64 kvm_hv_send_ipi(struct kvm_vcpu *current_vcpu, u64 ingpa, u64 outgpa,
 						    sizeof(send_ipi))))
 				return HV_STATUS_INVALID_HYPERCALL_INPUT;
 			sparse_banks[0] = send_ipi.cpu_mask;
-			irq.vector = send_ipi.vector;
+			vector = send_ipi.vector;
 		} else {
 			/* 'reserved' part of hv_send_ipi should be 0 */
 			if (unlikely(ingpa >> 32 != 0))
 				return HV_STATUS_INVALID_HYPERCALL_INPUT;
 			sparse_banks[0] = outgpa;
-			irq.vector = (u32)ingpa;
+			vector = (u32)ingpa;
 		}
 		all_cpus = false;
 		valid_bank_mask = BIT_ULL(0);
 
-		trace_kvm_hv_send_ipi(irq.vector, sparse_banks[0]);
+		trace_kvm_hv_send_ipi(vector, sparse_banks[0]);
 	} else {
 		if (unlikely(kvm_read_guest(kvm, ingpa, &send_ipi_ex,
 					    sizeof(send_ipi_ex))))
@@ -1446,7 +1441,7 @@ static u64 kvm_hv_send_ipi(struct kvm_vcpu *current_vcpu, u64 ingpa, u64 outgpa,
 					 send_ipi_ex.vp_set.format,
 					 send_ipi_ex.vp_set.valid_bank_mask);
 
-		irq.vector = send_ipi_ex.vector;
+		vector = send_ipi_ex.vector;
 		valid_bank_mask = send_ipi_ex.vp_set.valid_bank_mask;
 		sparse_banks_len = bitmap_weight(&valid_bank_mask, 64) *
 			sizeof(sparse_banks[0]);
@@ -1465,42 +1460,14 @@ static u64 kvm_hv_send_ipi(struct kvm_vcpu *current_vcpu, u64 ingpa, u64 outgpa,
 			return HV_STATUS_INVALID_HYPERCALL_INPUT;
 	}
 
-	if ((irq.vector < HV_IPI_LOW_VECTOR) ||
-	    (irq.vector > HV_IPI_HIGH_VECTOR))
+	if ((vector < HV_IPI_LOW_VECTOR) || (vector > HV_IPI_HIGH_VECTOR))
 		return HV_STATUS_INVALID_HYPERCALL_INPUT;
 
-	if (all_cpus || atomic_read(&hv->num_mismatched_vp_indexes)) {
-		kvm_for_each_vcpu(i, vcpu, kvm) {
-			if (all_cpus || hv_vcpu_in_sparse_set(
-				    &vcpu->arch.hyperv, sparse_banks,
-				    valid_bank_mask)) {
-				/* We fail only when APIC is disabled */
-				kvm_apic_set_irq(vcpu, &irq, NULL);
-			}
-		}
-		goto ret_success;
-	}
+	vcpu_mask = all_cpus ? NULL :
+		sparse_set_to_vcpu_mask(kvm, sparse_banks, valid_bank_mask,
+					vp_bitmap, vcpu_bitmap);
 
-	/*
-	 * num_mismatched_vp_indexes is zero so every vcpu has
-	 * vp_index == vcpu_idx.
-	 */
-	sbank = 0;
-	for_each_set_bit(bank, (unsigned long *)&valid_bank_mask, 64) {
-		for_each_set_bit(i, (unsigned long *)&sparse_banks[sbank], 64) {
-			u32 vp_index = bank * 64 + i;
-			struct kvm_vcpu *vcpu =
-				get_vcpu_by_vpidx(kvm, vp_index);
-
-			/* Unknown vCPU specified */
-			if (!vcpu)
-				continue;
-
-			/* We fail only when APIC is disabled */
-			kvm_apic_set_irq(vcpu, &irq, NULL);
-		}
-		sbank++;
-	}
+	send_ipi_vcpus_mask(kvm, vector, vcpu_mask);
 
 ret_success:
 	return HV_STATUS_SUCCESS;

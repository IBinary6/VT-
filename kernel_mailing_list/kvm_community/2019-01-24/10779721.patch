From patchwork Thu Jan 24 17:58:17 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Sean Christopherson <sean.j.christopherson@intel.com>
X-Patchwork-Id: 10779721
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 3528113B4
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu, 24 Jan 2019 17:59:03 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 25C6831B9D
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu, 24 Jan 2019 17:59:03 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 13EBB31BBB; Thu, 24 Jan 2019 17:59:03 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.9 required=2.0 tests=BAYES_00,MAILING_LIST_MULTI,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 865A931B9D
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu, 24 Jan 2019 17:59:02 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728196AbfAXR7C (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 24 Jan 2019 12:59:02 -0500
Received: from mga17.intel.com ([192.55.52.151]:56928 "EHLO mga17.intel.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1726252AbfAXR7B (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 24 Jan 2019 12:59:01 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga006.jf.intel.com ([10.7.209.51])
  by fmsmga107.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
 24 Jan 2019 09:59:01 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.56,517,1539673200";
   d="scan'208";a="110775875"
Received: from sjchrist-coffee.jf.intel.com ([10.54.74.14])
  by orsmga006.jf.intel.com with ESMTP; 24 Jan 2019 09:59:01 -0800
From: Sean Christopherson <sean.j.christopherson@intel.com>
To: Paolo Bonzini <pbonzini@redhat.com>,
 =?utf-8?b?UmFkaW0gS3LEjW3DocWZ?= <rkrcmar@redhat.com>
Cc: kvm@vger.kernel.org, Jim Mattson <jmattson@google.com>,
        Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Subject: [PATCH v2 00/29] KVM: VMX: Move vCPU-run to proper asm sub-routine
Date: Thu, 24 Jan 2019 09:58:17 -0800
Message-Id: <20190124175845.15926-1-sean.j.christopherson@intel.com>
X-Mailer: git-send-email 2.20.1
MIME-Version: 1.0
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

KVM's assembly for transitioning to/from a VMX guest is currently
implemented via inline asm.  At best it can be called "inscrutable", at
worst, well, that can't be printed here.

This series' ultimate goal is to move the transition code to a proper
assembly sub-routine that can be directly invoked from C code.
Unsurprisingly, making that happen requires a large number of patches
to carefully disarm all of the booby traps hiding in the shadows.

This series does NOT apply directly on the official KVM branches, but
rather on the official branches plus the patch that splits out a small
amount of vmx_vcpu_run() code to a helper, __vmx_vcpu_run()[1].  Adding
the helper function fixes a bug for kernel v5.0, i.e. absolutely should
be applied before this series, and not accounting for that change would
result in non-trivial conflicts.

A few patches in this series are carried over from the back half of the
series that moved VM-Enter and VM-Exit to proper assembly[2], but is
versioned as a different series given the much more ambitious end goal.

v1: https://patchwork.kernel.org/cover/10771525/

v2:
  - Fully tested 32-bit, amazingly there was no breakage.
  - Use 'b' and '=b' for asm constraints instead of trying to get fancy
    with 'bl' and '=ebx'. [Paolo]
  - Rename explicit VCPU reg indicides to __VCPU_REGS_R*. [Paolo]
  - Add Jim and Konrad's Reviewed-by tags.

[1] https://patchwork.kernel.org/patch/10765309/
[2] https://patchwork.kernel.org/cover/10739549/

Sean Christopherson (29):
  KVM: VMX: Compare only a single byte for VMCS' "launched" in vCPU-run
  KVM: nVMX: Check a single byte for VMCS "launched" in nested early
    checks
  KVM: VMX: Modify only RSP when creating a placeholder for guest's RCX
  KVM: VMX: Save RSI to an unused output in the vCPU-run asm blob
  KVM: VMX: Manually load RDX in vCPU-run asm blob
  KVM: VMX: Let the compiler save/load RDX during vCPU-run
  KVM: nVMX: Remove a rogue "rax" clobber from
    nested_vmx_check_vmentry_hw()
  KVM: nVMX: Drop STACK_FRAME_NON_STANDARD from
    nested_vmx_check_vmentry_hw()
  KVM: nVMX: Explicitly reference the scratch reg in nested early checks
  KVM: nVMX: Capture VM-Fail to a local var in
    nested_vmx_check_vmentry_hw()
  KVM: nVMX: Capture VM-Fail via CC_{SET,OUT} in nested early checks
  KVM: nVMX: Reference vmx->loaded_vmcs->launched directly
  KVM: nVMX: Let the compiler select the reg for holding HOST_RSP
  KVM: nVMX: Cache host_rsp on a per-VMCS basis
  KVM: VMX: Load/save guest CR2 via C code in __vmx_vcpu_run()
  KVM: VMX: Update VMCS.HOST_RSP via helper C function
  KVM: VMX: Pass "launched" directly to the vCPU-run asm blob
  KVM: VMX: Invert the ordering of saving guest/host scratch reg at
    VM-Enter
  KVM: VMX: Don't save guest registers after VM-Fail
  KVM: VMX: Use vcpu->arch.regs directly when saving/loading guest state
  KVM: x86: Explicitly #define the VCPU_REGS_* indices
  KVM: VMX: Use #defines in place of immediates in VM-Enter inline asm
  KVM: VMX: Create a stack frame in vCPU-run
  KVM: VMX: Move vCPU-run code to a proper assembly routine
  KVM: VMX: Fold __vmx_vcpu_run() back into vmx_vcpu_run()
  KVM: VMX: Rename ____vmx_vcpu_run() to __vmx_vcpu_run()
  KVM: VMX: Use RAX as the scratch register during vCPU-run
  KVM: VMX: Make the vCPU-run asm routine callable from C
  KVM: VMX: Reorder clearing of registers in the vCPU-run assembly flow

 arch/x86/include/asm/kvm_host.h      |  33 +++---
 arch/x86/include/asm/kvm_vcpu_regs.h |  25 +++++
 arch/x86/kvm/vmx/nested.c            |  53 ++++-----
 arch/x86/kvm/vmx/vmcs.h              |   1 +
 arch/x86/kvm/vmx/vmenter.S           | 159 ++++++++++++++++++++++++++
 arch/x86/kvm/vmx/vmx.c               | 160 +++------------------------
 arch/x86/kvm/vmx/vmx.h               |   3 +-
 7 files changed, 241 insertions(+), 193 deletions(-)
 create mode 100644 arch/x86/include/asm/kvm_vcpu_regs.h

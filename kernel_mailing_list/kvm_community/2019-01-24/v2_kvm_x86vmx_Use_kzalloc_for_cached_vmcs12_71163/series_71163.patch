From patchwork Thu Jan 24 21:48:20 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Tom Roeder <tmroeder@google.com>
X-Patchwork-Id: 10780177
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 29DA513B4
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu, 24 Jan 2019 21:48:57 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 04C322C65B
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu, 24 Jan 2019 21:48:57 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id E69302F6A8; Thu, 24 Jan 2019 21:48:56 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-15.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI,
	USER_IN_DEF_DKIM_WL autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4CCE12BDDB
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu, 24 Jan 2019 21:48:56 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727861AbfAXVsu (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 24 Jan 2019 16:48:50 -0500
Received: from mail-vk1-f201.google.com ([209.85.221.201]:35357 "EHLO
        mail-vk1-f201.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726269AbfAXVsu (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 24 Jan 2019 16:48:50 -0500
Received: by mail-vk1-f201.google.com with SMTP id o12so2120417vko.2
        for <kvm@vger.kernel.org>; Thu, 24 Jan 2019 13:48:49 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:message-id:mime-version:subject:from:to:cc;
        bh=CBf9ANq0HVSY89uYI9yBKKXPTmqHyAr/xQJ28QhdWOw=;
        b=wCrbD/Q9SM+PU9QD/lfuzAvsKHk0arQeIRyu6S0w8BsaA1aQI9DwUScalkSDCgtL/F
         lJ3YboP4r+PbiSySndGdomzYi2J3qtqgt1hD8r4q0RMuHDCohhBdDv1OegcZR2OORMJ4
         Mh3ZF4O3AiiiHADCaxv37eKOgg8szCYW2+eehVTFoX/jB1OH3xHYeqHw4w9jDBBYgc7+
         TGy5dK++K1IvnbSGT1W8MsF2LMtt/m0HRqK81tQWhlDGiRrOKriw9f+3qQXemAG2+69Q
         fnNKU35md0VBL5KRpkqKRXO5zkDHevKGz6ibF6WLJR3p8p7j9gUiaccZBrLIoU9QgLi6
         SF9A==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:message-id:mime-version:subject:from:to:cc;
        bh=CBf9ANq0HVSY89uYI9yBKKXPTmqHyAr/xQJ28QhdWOw=;
        b=USHPAh/VAWC70MW4MNWRoKsFCa64+lHwNpq7av5TcHX5FdnjtikVJdMJcJ+Ri6tYO0
         +AqY9vGWcGDm1bhVwmfhpnzyOpPyKDsDgMFWXTITZcOzwNxkfCssw/cWs4RTuCFficvo
         eOarcmyPlvsoamdCWuLViglNr5ADQWvyB9Eh/ifKw2vWb87hnMwkV+JrO0UCgHDSoe8p
         Lqjhgj8MF97dnNHp479tYmJzgbHvtZp23pbQGi3ETAeeNhSvRDOYq4hVhSMxitNcR5MY
         wW+MasLBeYDkZfG0ZzdsvhbKXueydpk5wphJ+kwatG3HNA74ezReC+VkEEdjF69HJQue
         BTnQ==
X-Gm-Message-State: AJcUukeAXsBrgR/fwLtnH1C5TazEl7WZ3/rL8HY4PRFoIADp12YwT1PJ
        i66pJO0wBTnzZUwkeCMuhZY86iHami/CTA==
X-Google-Smtp-Source: 
 ALg8bN7ZKDGlE+pO5krSzh+5JCL9nxdHr4Znx8d3RINtEvOHhCP1TPgj3T65RMo++32YQAdp9Ac2rYbOOIEqyQ==
X-Received: by 2002:a67:4b50:: with SMTP id y77mr6815156vsa.13.1548366528777;
 Thu, 24 Jan 2019 13:48:48 -0800 (PST)
Date: Thu, 24 Jan 2019 13:48:20 -0800
Message-Id: <20190124214820.187794-1-tmroeder@google.com>
Mime-Version: 1.0
X-Mailer: git-send-email 2.20.1.321.g9e740568ce-goog
Subject: [PATCH v2] kvm: x86/vmx: Use kzalloc for cached_vmcs12
From: Tom Roeder <tmroeder@google.com>
To: Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>
Cc: Jim Mattson <jmattson@google.com>,
 " =?utf-8?b?UmFkaW0gS3LEjW3DocWZ?= " <rkrcmar@redhat.com>,
 Liran Alon <liran.alon@oracle.com>, Thomas Gleixner <tglx@linutronix.de>,
 Ingo Molnar <mingo@redhat.com>, Borislav Petkov <bp@alien8.de>,
 "H . Peter Anvin" <hpa@zytor.com>, x86@kernel.org, kvm@vger.kernel.org,
 linux-kernel@vger.kernel.org, Tom Roeder <tmroeder@google.com>,
 syzbot+ded1696f6b50b615b630@syzkaller.appspotmail.com
Content-Type: text/plain; charset="UTF-8"
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

This changes the allocation of cached_vmcs12 to use kzalloc instead of
kmalloc. This removes the information leak found by Syzkaller (see
Reported-by) in this case and prevents similar leaks from happening
based on cached_vmcs12.

It also changes vmx_get_nested_state to copy out the full 4k VMCS12_SIZE
in copy_to_user rather than only the size of the struct.

Tested: rebuilt against head, booted, and ran the syszkaller repro
  https://syzkaller.appspot.com/text?tag=ReproC&x=174efca3400000 without
  observing any problems.

Reported-by: syzbot+ded1696f6b50b615b630@syzkaller.appspotmail.com
Signed-off-by: Tom Roeder <tmroeder@google.com>
---
Changelog since v1:
- Changed the copy_to_user calls in vmx_get_nested_state to copy the
  full 4k buffer.

 arch/x86/kvm/vmx/nested.c | 12 ++++++++----
 1 file changed, 8 insertions(+), 4 deletions(-)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index 2616bd2c7f2c7..ce81539238547 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -4140,11 +4140,11 @@ static int enter_vmx_operation(struct kvm_vcpu *vcpu)
 	if (r < 0)
 		goto out_vmcs02;
 
-	vmx->nested.cached_vmcs12 = kmalloc(VMCS12_SIZE, GFP_KERNEL);
+	vmx->nested.cached_vmcs12 = kzalloc(VMCS12_SIZE, GFP_KERNEL);
 	if (!vmx->nested.cached_vmcs12)
 		goto out_cached_vmcs12;
 
-	vmx->nested.cached_shadow_vmcs12 = kmalloc(VMCS12_SIZE, GFP_KERNEL);
+	vmx->nested.cached_shadow_vmcs12 = kzalloc(VMCS12_SIZE, GFP_KERNEL);
 	if (!vmx->nested.cached_shadow_vmcs12)
 		goto out_cached_shadow_vmcs12;
 
@@ -5263,13 +5263,17 @@ static int vmx_get_nested_state(struct kvm_vcpu *vcpu,
 			copy_shadow_to_vmcs12(vmx);
 	}
 
-	if (copy_to_user(user_kvm_nested_state->data, vmcs12, sizeof(*vmcs12)))
+	/*
+	 * Copy over the full allocated size of vmcs12 rather than just the size
+	 * of the struct.
+	 */
+	if (copy_to_user(user_kvm_nested_state->data, vmcs12, VMCS12_SIZE))
 		return -EFAULT;
 
 	if (nested_cpu_has_shadow_vmcs(vmcs12) &&
 	    vmcs12->vmcs_link_pointer != -1ull) {
 		if (copy_to_user(user_kvm_nested_state->data + VMCS12_SIZE,
-				 get_shadow_vmcs12(vcpu), sizeof(*vmcs12)))
+				 get_shadow_vmcs12(vcpu), VMCS12_SIZE))
 			return -EFAULT;
 	}
 

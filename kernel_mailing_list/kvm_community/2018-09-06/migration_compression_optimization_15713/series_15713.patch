From patchwork Thu Sep  6 07:00:59 2018
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Xiao Guangrong <guangrong.xiao@gmail.com>
X-Patchwork-Id: 10589935
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id ED488920
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:16 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E4D672A4FE
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:16 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id D8DD12A509; Thu,  6 Sep 2018 07:01:16 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7E1DF2A4FE
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:16 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727727AbeIFLfN (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 6 Sep 2018 07:35:13 -0400
Received: from mail-pl1-f177.google.com ([209.85.214.177]:41623 "EHLO
        mail-pl1-f177.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1727732AbeIFLfN (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 6 Sep 2018 07:35:13 -0400
Received: by mail-pl1-f177.google.com with SMTP id b12-v6so4514883plr.8
        for <kvm@vger.kernel.org>; Thu, 06 Sep 2018 00:01:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=rfQjjZoYN8ey6JzyEFUHP7aTftpMshBfTWmwy04gytM=;
        b=ZXHBPDR5o+zImRH2BS5ZWyh1BhK4II1mfOrl+ZCfAYlDHOtz942pD+eCUoaJmf2C/D
         HTHj0TSShk3r/RZp1+O8SZXL2I5YZMoRzh5yO0UDjuuChgi4bvTTWaBtTjPyP3QZMXZA
         mz0f0mitNdazo/8S2qFF6CY8AnzyzbYeYUxGCDyPSsDCOmMvf8/fMNGfrd/3BRG+7Oxj
         i8nvYWamTXbeOypZkfBZX5E3FiqJLpUCzdDXpVZ4+b7ueshy/ne+KT6PwnBpcXSih+I/
         g9MDEbMW+Wq46ioeDRUKIBFUdp6pcipbs1Ll2UslXU6epXeebT/9J8B9B595rQiX4ZQn
         TbiQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
         :references;
        bh=rfQjjZoYN8ey6JzyEFUHP7aTftpMshBfTWmwy04gytM=;
        b=ZLCc6VJlza1UAxL/lvJYcjq0mvhGt4TcLYGupxzRpxB6HWBfuFfd0nklzZ0mhpz2KI
         hgka92Gk8lLexxLZw30QD/kVl9IrsoEZCLEzxJ36u6+NqxofYl2v7xzDwQn2BWB6SzKd
         0BZKY6kuwDzZ42zif0yEJjKRt5bKftregl14NGurkUTZgqJn5rxUf74o+sodzQRXtdDr
         jZvs8yOcQH1K3+wWBQJCU3fIv8LAtkdiX9nj3NDyJeNpnUnPR9+iqT2rXrWGkOvZZHG5
         qXCQFWWMJTtJNHDqwXPzQTrj9RY4kip2dPHSngIuN6ng010n5UGRjdATc6UGNlhiZlVd
         p2Uw==
X-Gm-Message-State: APzg51Ay7cqGLjBu7Rnnq3XRcIpPRxUfvjmRuBdi0vD7XP2jDWoZrkI6
        GE2RXcyZOOm9vEf1rpzcIx4=
X-Google-Smtp-Source: 
 ANB0VdZKV2VHxnwkbzx3ENQfi43vyK6E3D0lT9iX06m7MhX3zauxiP/7EbvexJC+xul5HlMWpubMHA==
X-Received: by 2002:a17:902:be07:: with SMTP id
 r7-v6mr1282618pls.275.1536217274359;
        Thu, 06 Sep 2018 00:01:14 -0700 (PDT)
Received: from localhost.localdomain ([203.205.141.37])
        by smtp.gmail.com with ESMTPSA id
 u195-v6sm7697017pgb.21.2018.09.06.00.01.10
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Thu, 06 Sep 2018 00:01:13 -0700 (PDT)
From: guangrong.xiao@gmail.com
X-Google-Original-From: xiaoguangrong@tencent.com
To: pbonzini@redhat.com, mst@redhat.com, mtosatti@redhat.com
Cc: qemu-devel@nongnu.org, kvm@vger.kernel.org, dgilbert@redhat.com,
        peterx@redhat.com, wei.w.wang@intel.com, jiang.biao2@zte.com.cn,
        eblake@redhat.com, quintela@redhat.com,
        Xiao Guangrong <xiaoguangrong@tencent.com>
Subject: [PATCH v6 1/3] migration: do not flush_compressed_data at the end of
 iteration
Date: Thu,  6 Sep 2018 15:00:59 +0800
Message-Id: <20180906070101.27280-2-xiaoguangrong@tencent.com>
X-Mailer: git-send-email 2.14.4
In-Reply-To: <20180906070101.27280-1-xiaoguangrong@tencent.com>
References: <20180906070101.27280-1-xiaoguangrong@tencent.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

From: Xiao Guangrong <xiaoguangrong@tencent.com>

flush_compressed_data() needs to wait all compression threads to
finish their work, after that all threads are free until the
migration feeds new request to them, reducing its call can improve
the throughput and use CPU resource more effectively

We do not need to flush all threads at the end of iteration, the
data can be kept locally until the memory block is changed or
memory migration starts over in that case we will meet a dirtied
page which may still exists in compression threads's ring

Signed-off-by: Xiao Guangrong <xiaoguangrong@tencent.com>
Reviewed-by: Juan Quintela <quintela@redhat.com>
---
 migration/ram.c | 18 +++++++++++-------
 1 file changed, 11 insertions(+), 7 deletions(-)

diff --git a/migration/ram.c b/migration/ram.c
index 2add09174d..e152831254 100644
--- a/migration/ram.c
+++ b/migration/ram.c
@@ -1996,17 +1996,22 @@ static bool find_dirty_block(RAMState *rs, PageSearchStatus *pss, bool *again)
         pss->page = 0;
         pss->block = QLIST_NEXT_RCU(pss->block, next);
         if (!pss->block) {
+            /*
+             * If memory migration starts over, we will meet a dirtied page
+             * which may still exists in compression threads's ring, so we
+             * should flush the compressed data to make sure the new page
+             * is not overwritten by the old one in the destination.
+             *
+             * Also If xbzrle is on, stop using the data compression at this
+             * point. In theory, xbzrle can do better than compression.
+             */
+            flush_compressed_data(rs);
+
             /* Hit the end of the list */
             pss->block = QLIST_FIRST_RCU(&ram_list.blocks);
             /* Flag that we've looped */
             pss->complete_round = true;
             rs->ram_bulk_stage = false;
-            if (migrate_use_xbzrle()) {
-                /* If xbzrle is on, stop using the data compression at this
-                 * point. In theory, xbzrle can do better than compression.
-                 */
-                flush_compressed_data(rs);
-            }
         }
         /* Didn't find anything this time, but try again on the new block */
         *again = true;
@@ -3219,7 +3224,6 @@ static int ram_save_iterate(QEMUFile *f, void *opaque)
         }
         i++;
     }
-    flush_compressed_data(rs);
     rcu_read_unlock();
 
     /*

From patchwork Thu Sep  6 07:01:00 2018
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Xiao Guangrong <guangrong.xiao@gmail.com>
X-Patchwork-Id: 10589937
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 95EC1174C
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:22 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8939E2A4FE
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:22 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7D82A2A509; Thu,  6 Sep 2018 07:01:22 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D73BC2A4FE
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:21 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727735AbeIFLfS (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 6 Sep 2018 07:35:18 -0400
Received: from mail-pg1-f193.google.com ([209.85.215.193]:37783 "EHLO
        mail-pg1-f193.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726411AbeIFLfS (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 6 Sep 2018 07:35:18 -0400
Received: by mail-pg1-f193.google.com with SMTP id 2-v6so4724015pgo.4
        for <kvm@vger.kernel.org>; Thu, 06 Sep 2018 00:01:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=pt4nvbP+U1jEtDfLwvgl4Hy4NKYiBNWVYv3Xrchqpfk=;
        b=ZvuyTV3T+5kcdAR4Mla16fkju9GltdYIrTNDGq1O2uL/Um9cInGvcYOr2ejWRPknxG
         z4UD0zmYDr3Qo2irC9fubuDOJRT3pY29+sZyuP5hRdaXVpPphoS2/knY5OC9DO7Q8Rb8
         YbWvcjKEOr6vojAcOCNtQV43oVPsuht/tpSjZUwfgWBEJRo19yrTabRscw8zCbpSiU5V
         0G9XTv0UojWmNr29lMnDUDjPVS8vEKdDSOoItZkLPw7Ep8A4sZIYALC+QwMfUaK5X1CA
         Ejn7WBGBzBN+xbK11Wry14ZqeuXfI1kBguONZpTJ8NVKaY7+/CR0Eh0B7LQsr4DDe99N
         YgOQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
         :references;
        bh=pt4nvbP+U1jEtDfLwvgl4Hy4NKYiBNWVYv3Xrchqpfk=;
        b=dn9U4d7MAPMfjEZFE5l6iXp5JkhpgAoh1GDCqINeKzmEVkQhDHxwAI44YMLcWG+WhA
         V+gemSN0GhP12jlsNpT/DbGEH+YFgKK/xQIzh739TE++nHVC0VjyC6n+sdJ+9vI6X/aK
         B81OXqAMOitSR008OcHmc/AZPtzQiCO6GhMwn5a2z2jLebQc0scjU98hYJEJhUP4x/UL
         jay++NnLJLGaR1BtwF2sF5/A5KUgmtUAwLu41O7K9yghMieM1jrfYry2p3lEd6KhJbSX
         vwSksdXidsVoWQUSiRjZAIKqdooDRuOCA0nu2/4vuIWxY2dbRtVUF/gBfAHnuoJfN3X0
         +vUA==
X-Gm-Message-State: APzg51CsfuxbraHg0hv+cjWrwEoM6WruT9mBGVMri+Z3RUo5BSjGjXZt
        9rn6E5LTlMZ7nKy1QYKD6lI=
X-Google-Smtp-Source: 
 ANB0VdbMmRMAGOosW9lp8F2f59IP30YzhVNEDRqpokbVU0NVx+KWEwaZpx4OhXziA+PD3UGEfplLkw==
X-Received: by 2002:a63:8b44:: with SMTP id
 j65-v6mr1344290pge.325.1536217278582;
        Thu, 06 Sep 2018 00:01:18 -0700 (PDT)
Received: from localhost.localdomain ([203.205.141.37])
        by smtp.gmail.com with ESMTPSA id
 u195-v6sm7697017pgb.21.2018.09.06.00.01.14
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Thu, 06 Sep 2018 00:01:18 -0700 (PDT)
From: guangrong.xiao@gmail.com
X-Google-Original-From: xiaoguangrong@tencent.com
To: pbonzini@redhat.com, mst@redhat.com, mtosatti@redhat.com
Cc: qemu-devel@nongnu.org, kvm@vger.kernel.org, dgilbert@redhat.com,
        peterx@redhat.com, wei.w.wang@intel.com, jiang.biao2@zte.com.cn,
        eblake@redhat.com, quintela@redhat.com,
        Xiao Guangrong <xiaoguangrong@tencent.com>
Subject: [PATCH v6 2/3] migration: show the statistics of compression
Date: Thu,  6 Sep 2018 15:01:00 +0800
Message-Id: <20180906070101.27280-3-xiaoguangrong@tencent.com>
X-Mailer: git-send-email 2.14.4
In-Reply-To: <20180906070101.27280-1-xiaoguangrong@tencent.com>
References: <20180906070101.27280-1-xiaoguangrong@tencent.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

From: Xiao Guangrong <xiaoguangrong@tencent.com>

Currently, it includes:
pages: amount of pages compressed and transferred to the target VM
busy: amount of count that no free thread to compress data
busy-rate: rate of thread busy
compressed-size: amount of bytes after compression
compression-rate: rate of compressed size

Reviewed-by: Juan Quintela <quintela@redhat.com>
Reviewed-by: Peter Xu <peterx@redhat.com>
Signed-off-by: Xiao Guangrong <xiaoguangrong@tencent.com>
---
 hmp.c                 | 13 +++++++++++++
 migration/migration.c | 12 ++++++++++++
 migration/ram.c       | 41 ++++++++++++++++++++++++++++++++++++++++-
 migration/ram.h       |  1 +
 qapi/migration.json   | 26 +++++++++++++++++++++++++-
 5 files changed, 91 insertions(+), 2 deletions(-)

diff --git a/hmp.c b/hmp.c
index 4975fa56b0..f57b23d889 100644
--- a/hmp.c
+++ b/hmp.c
@@ -271,6 +271,19 @@ void hmp_info_migrate(Monitor *mon, const QDict *qdict)
                        info->xbzrle_cache->overflow);
     }
 
+    if (info->has_compression) {
+        monitor_printf(mon, "compression pages: %" PRIu64 " pages\n",
+                       info->compression->pages);
+        monitor_printf(mon, "compression busy: %" PRIu64 "\n",
+                       info->compression->busy);
+        monitor_printf(mon, "compression busy rate: %0.2f\n",
+                       info->compression->busy_rate);
+        monitor_printf(mon, "compressed size: %" PRIu64 "\n",
+                       info->compression->compressed_size);
+        monitor_printf(mon, "compression rate: %0.2f\n",
+                       info->compression->compression_rate);
+    }
+
     if (info->has_cpu_throttle_percentage) {
         monitor_printf(mon, "cpu throttle percentage: %" PRIu64 "\n",
                        info->cpu_throttle_percentage);
diff --git a/migration/migration.c b/migration/migration.c
index 4b316ec343..f1d662f928 100644
--- a/migration/migration.c
+++ b/migration/migration.c
@@ -758,6 +758,18 @@ static void populate_ram_info(MigrationInfo *info, MigrationState *s)
         info->xbzrle_cache->overflow = xbzrle_counters.overflow;
     }
 
+    if (migrate_use_compression()) {
+        info->has_compression = true;
+        info->compression = g_malloc0(sizeof(*info->compression));
+        info->compression->pages = compression_counters.pages;
+        info->compression->busy = compression_counters.busy;
+        info->compression->busy_rate = compression_counters.busy_rate;
+        info->compression->compressed_size =
+                                    compression_counters.compressed_size;
+        info->compression->compression_rate =
+                                    compression_counters.compression_rate;
+    }
+
     if (cpu_throttle_active()) {
         info->has_cpu_throttle_percentage = true;
         info->cpu_throttle_percentage = cpu_throttle_get_percentage();
diff --git a/migration/ram.c b/migration/ram.c
index e152831254..65a563993d 100644
--- a/migration/ram.c
+++ b/migration/ram.c
@@ -301,6 +301,15 @@ struct RAMState {
     uint64_t num_dirty_pages_period;
     /* xbzrle misses since the beginning of the period */
     uint64_t xbzrle_cache_miss_prev;
+
+    /* compression statistics since the beginning of the period */
+    /* amount of count that no free thread to compress data */
+    uint64_t compress_thread_busy_prev;
+    /* amount bytes after compression */
+    uint64_t compressed_size_prev;
+    /* amount of compressed pages */
+    uint64_t compress_pages_prev;
+
     /* total handled target pages at the beginning of period */
     uint64_t target_page_count_prev;
     /* total handled target pages since start */
@@ -338,6 +347,8 @@ struct PageSearchStatus {
 };
 typedef struct PageSearchStatus PageSearchStatus;
 
+CompressionStats compression_counters;
+
 struct CompressParam {
     bool done;
     bool quit;
@@ -1593,6 +1604,7 @@ uint64_t ram_pagesize_summary(void)
 static void migration_update_rates(RAMState *rs, int64_t end_time)
 {
     uint64_t page_count = rs->target_page_count - rs->target_page_count_prev;
+    double compressed_size;
 
     /* calculate period counters */
     ram_counters.dirty_pages_rate = rs->num_dirty_pages_period * 1000
@@ -1607,6 +1619,26 @@ static void migration_update_rates(RAMState *rs, int64_t end_time)
             rs->xbzrle_cache_miss_prev) / page_count;
         rs->xbzrle_cache_miss_prev = xbzrle_counters.cache_miss;
     }
+
+    if (migrate_use_compression()) {
+        compression_counters.busy_rate = (double)(compression_counters.busy -
+            rs->compress_thread_busy_prev) / page_count;
+        rs->compress_thread_busy_prev = compression_counters.busy;
+
+        compressed_size = compression_counters.compressed_size -
+                          rs->compressed_size_prev;
+        if (compressed_size) {
+            double uncompressed_size = (compression_counters.pages -
+                                    rs->compress_pages_prev) * TARGET_PAGE_SIZE;
+
+            /* Compression-Ratio = Uncompressed-size / Compressed-size */
+            compression_counters.compression_rate =
+                                        uncompressed_size / compressed_size;
+
+            rs->compress_pages_prev = compression_counters.pages;
+            rs->compressed_size_prev = compression_counters.compressed_size;
+        }
+    }
 }
 
 static void migration_bitmap_sync(RAMState *rs)
@@ -1888,10 +1920,16 @@ exit:
 static void
 update_compress_thread_counts(const CompressParam *param, int bytes_xmit)
 {
+    ram_counters.transferred += bytes_xmit;
+
     if (param->zero_page) {
         ram_counters.duplicate++;
+        return;
     }
-    ram_counters.transferred += bytes_xmit;
+
+    /* 8 means a header with RAM_SAVE_FLAG_CONTINUE. */
+    compression_counters.compressed_size += bytes_xmit - 8;
+    compression_counters.pages++;
 }
 
 static void flush_compressed_data(RAMState *rs)
@@ -2264,6 +2302,7 @@ static bool save_compress_page(RAMState *rs, RAMBlock *block, ram_addr_t offset)
         return true;
     }
 
+    compression_counters.busy++;
     return false;
 }
 
diff --git a/migration/ram.h b/migration/ram.h
index 457bf54b8c..a139066846 100644
--- a/migration/ram.h
+++ b/migration/ram.h
@@ -36,6 +36,7 @@
 
 extern MigrationStats ram_counters;
 extern XBZRLECacheStats xbzrle_counters;
+extern CompressionStats compression_counters;
 
 int xbzrle_cache_resize(int64_t new_size, Error **errp);
 uint64_t ram_bytes_remaining(void);
diff --git a/qapi/migration.json b/qapi/migration.json
index f62d3f9a4b..6e8c21258a 100644
--- a/qapi/migration.json
+++ b/qapi/migration.json
@@ -75,6 +75,27 @@
            'cache-miss': 'int', 'cache-miss-rate': 'number',
            'overflow': 'int' } }
 
+##
+# @CompressionStats:
+#
+# Detailed migration compression statistics
+#
+# @pages: amount of pages compressed and transferred to the target VM
+#
+# @busy: count of times that no free thread was available to compress data
+#
+# @busy-rate: rate of thread busy
+#
+# @compressed-size: amount of bytes after compression
+#
+# @compression-rate: rate of compressed size
+#
+# Since: 3.1
+##
+{ 'struct': 'CompressionStats',
+  'data': {'pages': 'int', 'busy': 'int', 'busy-rate': 'number',
+	   'compressed-size': 'int', 'compression-rate': 'number' } }
+
 ##
 # @MigrationStatus:
 #
@@ -172,6 +193,8 @@
 #           only present when the postcopy-blocktime migration capability
 #           is enabled. (Since 3.0)
 #
+# @compression: migration compression statistics, only returned if compression
+#           feature is on and status is 'active' or 'completed' (Since 3.1)
 #
 # Since: 0.14.0
 ##
@@ -186,7 +209,8 @@
            '*cpu-throttle-percentage': 'int',
            '*error-desc': 'str',
            '*postcopy-blocktime' : 'uint32',
-           '*postcopy-vcpu-blocktime': ['uint32']} }
+           '*postcopy-vcpu-blocktime': ['uint32'],
+           '*compression': 'CompressionStats'} }
 
 ##
 # @query-migrate:

From patchwork Thu Sep  6 07:01:01 2018
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Xiao Guangrong <guangrong.xiao@gmail.com>
X-Patchwork-Id: 10589939
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id E31D3174C
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:24 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id DC04C2A4FE
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:24 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id D025E2A509; Thu,  6 Sep 2018 07:01:24 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8673A2A4FE
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  6 Sep 2018 07:01:24 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727739AbeIFLfV (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 6 Sep 2018 07:35:21 -0400
Received: from mail-pl1-f175.google.com ([209.85.214.175]:44204 "EHLO
        mail-pl1-f175.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1727732AbeIFLfV (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 6 Sep 2018 07:35:21 -0400
Received: by mail-pl1-f175.google.com with SMTP id ba4-v6so4510662plb.11
        for <kvm@vger.kernel.org>; Thu, 06 Sep 2018 00:01:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=x/yvF6rLcefKp4F7fvRvQvJ/7u8JYj73jUiGjQmP4Es=;
        b=ka0+MefJgOuByr+8xAauEiWM+Y10aRNyGKhOpj01m6CrjLtqlBfd+oMCv0/SxFBVkS
         wAtCAznapZi8qQKYc+2NkbczDdPUNdNy+aFYWkeozftaUzKfGdMGOlDORePbbXD25qnG
         Zzr1X9OAA2q8xJPJ2HQsODxO75L/W9rHGY1n6qj9HK00PA5ln316pinsGfMUqV0ayXAx
         AJdVLzNm8u3y+/vy8V61HIiBCVV4f2IP8nfVrB1ghoIdoQsR9EE7ecF/3ZQ2kzwlTH2f
         VY5rqFh2Be7Ug3YBJ5+/RTd0dWaw0qth3hn/u29Bhvfsc8XyCXhHxTIGdmFtd7Y18r2c
         inDA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
         :references;
        bh=x/yvF6rLcefKp4F7fvRvQvJ/7u8JYj73jUiGjQmP4Es=;
        b=T4zx0ckRh56KCb7Ob3doxlGCtDrhYCAVBsAiYy0sgvAETo8+s0H4Z9/tc3Xj3SDL9V
         z0SNnLBzy14TTSBLpBIZMJYjigFVahoeiXAnOxi074lKKSMvSppIN1gkcGP33XYX5K8x
         gyvHdj6isRUyuph67gphxu35gFd3a0RdzISenqy02IgUlgXPzcwYAqatP42US0Ev2CDF
         PS4Mwd6p2qHnOFNyf00UJjrrwUKN3HQk0zmRUpHQKAFgTLVRz+pl+tos4AhC+g86fklN
         Y2mD7MRnUIT9Wk9+9udI0mADAUa/065REb3lctzcvZiyXT0jXvp+iqpgy5boe/4QOvHs
         T4fw==
X-Gm-Message-State: APzg51B/yZdt1ADFMhbuyUDm+lP9DnXzH3PKBf3QeTPadXyRN5tBR31x
        fekIYziCf3ZkQcV3xK1iLSA=
X-Google-Smtp-Source: 
 ANB0VdbQT7TO6eZ8x2+rchvv5LvbDSEl3Ypx00Jpw6oGROe0MNoJDhbAj3mXFYqnZ4iMlMDoOMHdGw==
X-Received: by 2002:a17:902:33c2:: with SMTP id
 b60-v6mr1323576plc.11.1536217282741;
        Thu, 06 Sep 2018 00:01:22 -0700 (PDT)
Received: from localhost.localdomain ([203.205.141.37])
        by smtp.gmail.com with ESMTPSA id
 u195-v6sm7697017pgb.21.2018.09.06.00.01.18
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Thu, 06 Sep 2018 00:01:22 -0700 (PDT)
From: guangrong.xiao@gmail.com
X-Google-Original-From: xiaoguangrong@tencent.com
To: pbonzini@redhat.com, mst@redhat.com, mtosatti@redhat.com
Cc: qemu-devel@nongnu.org, kvm@vger.kernel.org, dgilbert@redhat.com,
        peterx@redhat.com, wei.w.wang@intel.com, jiang.biao2@zte.com.cn,
        eblake@redhat.com, quintela@redhat.com,
        Xiao Guangrong <xiaoguangrong@tencent.com>
Subject: [PATCH v6 3/3] migration: use save_page_use_compression in
 flush_compressed_data
Date: Thu,  6 Sep 2018 15:01:01 +0800
Message-Id: <20180906070101.27280-4-xiaoguangrong@tencent.com>
X-Mailer: git-send-email 2.14.4
In-Reply-To: <20180906070101.27280-1-xiaoguangrong@tencent.com>
References: <20180906070101.27280-1-xiaoguangrong@tencent.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

From: Xiao Guangrong <xiaoguangrong@tencent.com>

It avoids to touch compression locks if xbzrle and compression
are both enabled

Signed-off-by: Xiao Guangrong <xiaoguangrong@tencent.com>
Reviewed-by: Juan Quintela <quintela@redhat.com>
---
 migration/ram.c | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/migration/ram.c b/migration/ram.c
index 65a563993d..747dd9208b 100644
--- a/migration/ram.c
+++ b/migration/ram.c
@@ -1932,11 +1932,13 @@ update_compress_thread_counts(const CompressParam *param, int bytes_xmit)
     compression_counters.pages++;
 }
 
+static bool save_page_use_compression(RAMState *rs);
+
 static void flush_compressed_data(RAMState *rs)
 {
     int idx, len, thread_count;
 
-    if (!migrate_use_compression()) {
+    if (!save_page_use_compression(rs)) {
         return;
     }
     thread_count = migrate_compress_threads();
